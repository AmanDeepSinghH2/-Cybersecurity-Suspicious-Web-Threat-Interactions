{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27dae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Deep Singh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - AUC: 0.7022 - Precision: 0.5922 - Recall: 0.6339 - accuracy: 0.6415 - loss: 6.6797 - val_AUC: 0.7753 - val_Precision: 0.8825 - val_Recall: 0.4496 - val_accuracy: 0.7261 - val_loss: 6.0645 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - AUC: 0.7022 - Precision: 0.5922 - Recall: 0.6339 - accuracy: 0.6415 - loss: 6.6797 - val_AUC: 0.7753 - val_Precision: 0.8825 - val_Recall: 0.4496 - val_accuracy: 0.7261 - val_loss: 6.0645 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.7875 - Precision: 0.6906 - Recall: 0.6845 - accuracy: 0.7221 - loss: 5.5350 - val_AUC: 0.8102 - val_Precision: 0.9918 - val_Recall: 0.3533 - val_accuracy: 0.7084 - val_loss: 5.0521 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.7875 - Precision: 0.6906 - Recall: 0.6845 - accuracy: 0.7221 - loss: 5.5350 - val_AUC: 0.8102 - val_Precision: 0.9918 - val_Recall: 0.3533 - val_accuracy: 0.7084 - val_loss: 5.0521 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8149 - Precision: 0.7450 - Recall: 0.6966 - accuracy: 0.7580 - loss: 4.5613 - val_AUC: 0.8383 - val_Precision: 0.9913 - val_Recall: 0.3328 - val_accuracy: 0.6992 - val_loss: 4.1793 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8149 - Precision: 0.7450 - Recall: 0.6966 - accuracy: 0.7580 - loss: 4.5613 - val_AUC: 0.8383 - val_Precision: 0.9913 - val_Recall: 0.3328 - val_accuracy: 0.6992 - val_loss: 4.1793 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8314 - Precision: 0.7622 - Recall: 0.7054 - accuracy: 0.7701 - loss: 3.7489 - val_AUC: 0.8554 - val_Precision: 0.9832 - val_Recall: 0.5124 - val_accuracy: 0.7772 - val_loss: 3.3926 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8314 - Precision: 0.7622 - Recall: 0.7054 - accuracy: 0.7701 - loss: 3.7489 - val_AUC: 0.8554 - val_Precision: 0.9832 - val_Recall: 0.5124 - val_accuracy: 0.7772 - val_loss: 3.3926 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8527 - Precision: 0.8090 - Recall: 0.7285 - accuracy: 0.8019 - loss: 3.0625 - val_AUC: 0.8655 - val_Precision: 0.9827 - val_Recall: 0.5810 - val_accuracy: 0.8073 - val_loss: 2.7694 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8527 - Precision: 0.8090 - Recall: 0.7285 - accuracy: 0.8019 - loss: 3.0625 - val_AUC: 0.8655 - val_Precision: 0.9827 - val_Recall: 0.5810 - val_accuracy: 0.8073 - val_loss: 2.7694 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8569 - Precision: 0.8312 - Recall: 0.7245 - accuracy: 0.8112 - loss: 2.5173 - val_AUC: 0.8732 - val_Precision: 0.9782 - val_Recall: 0.6540 - val_accuracy: 0.8381 - val_loss: 2.2476 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8569 - Precision: 0.8312 - Recall: 0.7245 - accuracy: 0.8112 - loss: 2.5173 - val_AUC: 0.8732 - val_Precision: 0.9782 - val_Recall: 0.6540 - val_accuracy: 0.8381 - val_loss: 2.2476 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8699 - Precision: 0.8427 - Recall: 0.7392 - accuracy: 0.8219 - loss: 2.0660 - val_AUC: 0.8724 - val_Precision: 0.9647 - val_Recall: 0.6774 - val_accuracy: 0.8440 - val_loss: 1.8613 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8699 - Precision: 0.8427 - Recall: 0.7392 - accuracy: 0.8219 - loss: 2.0660 - val_AUC: 0.8724 - val_Precision: 0.9647 - val_Recall: 0.6774 - val_accuracy: 0.8440 - val_loss: 1.8613 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8715 - Precision: 0.8542 - Recall: 0.7373 - accuracy: 0.8265 - loss: 1.7234 - val_AUC: 0.8784 - val_Precision: 0.9766 - val_Recall: 0.6715 - val_accuracy: 0.8453 - val_loss: 1.5532 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8715 - Precision: 0.8542 - Recall: 0.7373 - accuracy: 0.8265 - loss: 1.7234 - val_AUC: 0.8784 - val_Precision: 0.9766 - val_Recall: 0.6715 - val_accuracy: 0.8453 - val_loss: 1.5532 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8758 - Precision: 0.8647 - Recall: 0.7480 - accuracy: 0.8352 - loss: 1.4457 - val_AUC: 0.8789 - val_Precision: 0.9828 - val_Recall: 0.6686 - val_accuracy: 0.8460 - val_loss: 1.3108 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8758 - Precision: 0.8647 - Recall: 0.7480 - accuracy: 0.8352 - loss: 1.4457 - val_AUC: 0.8789 - val_Precision: 0.9828 - val_Recall: 0.6686 - val_accuracy: 0.8460 - val_loss: 1.3108 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8791 - Precision: 0.8702 - Recall: 0.7524 - accuracy: 0.8393 - loss: 1.2273 - val_AUC: 0.8747 - val_Precision: 0.9735 - val_Recall: 0.6978 - val_accuracy: 0.8558 - val_loss: 1.1148 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8791 - Precision: 0.8702 - Recall: 0.7524 - accuracy: 0.8393 - loss: 1.2273 - val_AUC: 0.8747 - val_Precision: 0.9735 - val_Recall: 0.6978 - val_accuracy: 0.8558 - val_loss: 1.1148 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8756 - Precision: 0.8732 - Recall: 0.7476 - accuracy: 0.8388 - loss: 1.0663 - val_AUC: 0.8731 - val_Precision: 0.9641 - val_Recall: 0.7051 - val_accuracy: 0.8558 - val_loss: 0.9757 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8756 - Precision: 0.8732 - Recall: 0.7476 - accuracy: 0.8388 - loss: 1.0663 - val_AUC: 0.8731 - val_Precision: 0.9641 - val_Recall: 0.7051 - val_accuracy: 0.8558 - val_loss: 0.9757 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8762 - Precision: 0.8888 - Recall: 0.7539 - accuracy: 0.8479 - loss: 0.9292 - val_AUC: 0.8725 - val_Precision: 0.9848 - val_Recall: 0.6642 - val_accuracy: 0.8447 - val_loss: 0.8678 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8762 - Precision: 0.8888 - Recall: 0.7539 - accuracy: 0.8479 - loss: 0.9292 - val_AUC: 0.8725 - val_Precision: 0.9848 - val_Recall: 0.6642 - val_accuracy: 0.8447 - val_loss: 0.8678 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8845 - Precision: 0.8925 - Recall: 0.7524 - accuracy: 0.8489 - loss: 0.8159 - val_AUC: 0.8683 - val_Precision: 0.9847 - val_Recall: 0.6599 - val_accuracy: 0.8427 - val_loss: 0.7811 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8845 - Precision: 0.8925 - Recall: 0.7524 - accuracy: 0.8489 - loss: 0.8159 - val_AUC: 0.8683 - val_Precision: 0.9847 - val_Recall: 0.6599 - val_accuracy: 0.8427 - val_loss: 0.7811 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8864 - Precision: 0.8931 - Recall: 0.7605 - accuracy: 0.8524 - loss: 0.7331 - val_AUC: 0.8664 - val_Precision: 0.9834 - val_Recall: 0.6905 - val_accuracy: 0.8558 - val_loss: 0.7021 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8864 - Precision: 0.8931 - Recall: 0.7605 - accuracy: 0.8524 - loss: 0.7331 - val_AUC: 0.8664 - val_Precision: 0.9834 - val_Recall: 0.6905 - val_accuracy: 0.8558 - val_loss: 0.7021 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8842 - Precision: 0.8989 - Recall: 0.7535 - accuracy: 0.8520 - loss: 0.6743 - val_AUC: 0.8744 - val_Precision: 0.9743 - val_Recall: 0.7182 - val_accuracy: 0.8650 - val_loss: 0.6293 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8842 - Precision: 0.8989 - Recall: 0.7535 - accuracy: 0.8520 - loss: 0.6743 - val_AUC: 0.8744 - val_Precision: 0.9743 - val_Recall: 0.7182 - val_accuracy: 0.8650 - val_loss: 0.6293 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8850 - Precision: 0.9132 - Recall: 0.7605 - accuracy: 0.8607 - loss: 0.6163 - val_AUC: 0.8717 - val_Precision: 0.9743 - val_Recall: 0.7182 - val_accuracy: 0.8650 - val_loss: 0.5837 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8850 - Precision: 0.9132 - Recall: 0.7605 - accuracy: 0.8607 - loss: 0.6163 - val_AUC: 0.8717 - val_Precision: 0.9743 - val_Recall: 0.7182 - val_accuracy: 0.8650 - val_loss: 0.5837 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8854 - Precision: 0.9157 - Recall: 0.7531 - accuracy: 0.8588 - loss: 0.5813 - val_AUC: 0.8762 - val_Precision: 0.9859 - val_Recall: 0.7124 - val_accuracy: 0.8663 - val_loss: 0.5520 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8854 - Precision: 0.9157 - Recall: 0.7531 - accuracy: 0.8588 - loss: 0.5813 - val_AUC: 0.8762 - val_Precision: 0.9859 - val_Recall: 0.7124 - val_accuracy: 0.8663 - val_loss: 0.5520 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8868 - Precision: 0.9065 - Recall: 0.7612 - accuracy: 0.8583 - loss: 0.5536 - val_AUC: 0.8783 - val_Precision: 0.9541 - val_Recall: 0.7285 - val_accuracy: 0.8624 - val_loss: 0.5280 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8868 - Precision: 0.9065 - Recall: 0.7612 - accuracy: 0.8583 - loss: 0.5536 - val_AUC: 0.8783 - val_Precision: 0.9541 - val_Recall: 0.7285 - val_accuracy: 0.8624 - val_loss: 0.5280 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8815 - Precision: 0.9161 - Recall: 0.7572 - accuracy: 0.8606 - loss: 0.5316 - val_AUC: 0.8771 - val_Precision: 0.9729 - val_Recall: 0.7343 - val_accuracy: 0.8716 - val_loss: 0.4906 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8815 - Precision: 0.9161 - Recall: 0.7572 - accuracy: 0.8606 - loss: 0.5316 - val_AUC: 0.8771 - val_Precision: 0.9729 - val_Recall: 0.7343 - val_accuracy: 0.8716 - val_loss: 0.4906 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8866 - Precision: 0.9291 - Recall: 0.7601 - accuracy: 0.8670 - loss: 0.4995 - val_AUC: 0.8740 - val_Precision: 0.9726 - val_Recall: 0.7255 - val_accuracy: 0.8676 - val_loss: 0.4847 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8866 - Precision: 0.9291 - Recall: 0.7601 - accuracy: 0.8670 - loss: 0.4995 - val_AUC: 0.8740 - val_Precision: 0.9726 - val_Recall: 0.7255 - val_accuracy: 0.8676 - val_loss: 0.4847 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8839 - Precision: 0.9247 - Recall: 0.7608 - accuracy: 0.8655 - loss: 0.4870 - val_AUC: 0.8742 - val_Precision: 0.9409 - val_Recall: 0.7431 - val_accuracy: 0.8637 - val_loss: 0.4777 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8839 - Precision: 0.9247 - Recall: 0.7608 - accuracy: 0.8655 - loss: 0.4870 - val_AUC: 0.8742 - val_Precision: 0.9409 - val_Recall: 0.7431 - val_accuracy: 0.8637 - val_loss: 0.4777 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9335 - Recall: 0.7623 - accuracy: 0.8696 - loss: 0.4673 - val_AUC: 0.8752 - val_Precision: 0.9245 - val_Recall: 0.7328 - val_accuracy: 0.8532 - val_loss: 0.4701 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9335 - Recall: 0.7623 - accuracy: 0.8696 - loss: 0.4673 - val_AUC: 0.8752 - val_Precision: 0.9245 - val_Recall: 0.7328 - val_accuracy: 0.8532 - val_loss: 0.4701 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9289 - Recall: 0.7616 - accuracy: 0.8674 - loss: 0.4571 - val_AUC: 0.8771 - val_Precision: 0.9745 - val_Recall: 0.7255 - val_accuracy: 0.8683 - val_loss: 0.4397 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9289 - Recall: 0.7616 - accuracy: 0.8674 - loss: 0.4571 - val_AUC: 0.8771 - val_Precision: 0.9745 - val_Recall: 0.7255 - val_accuracy: 0.8683 - val_loss: 0.4397 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8874 - Precision: 0.9308 - Recall: 0.7605 - accuracy: 0.8678 - loss: 0.4513 - val_AUC: 0.8836 - val_Precision: 0.9822 - val_Recall: 0.7241 - val_accuracy: 0.8702 - val_loss: 0.4353 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8874 - Precision: 0.9308 - Recall: 0.7605 - accuracy: 0.8678 - loss: 0.4513 - val_AUC: 0.8836 - val_Precision: 0.9822 - val_Recall: 0.7241 - val_accuracy: 0.8702 - val_loss: 0.4353 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8912 - Precision: 0.9396 - Recall: 0.7590 - accuracy: 0.8706 - loss: 0.4398 - val_AUC: 0.8787 - val_Precision: 0.9457 - val_Recall: 0.7372 - val_accuracy: 0.8630 - val_loss: 0.4305 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8912 - Precision: 0.9396 - Recall: 0.7590 - accuracy: 0.8706 - loss: 0.4398 - val_AUC: 0.8787 - val_Precision: 0.9457 - val_Recall: 0.7372 - val_accuracy: 0.8630 - val_loss: 0.4305 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8893 - Precision: 0.9300 - Recall: 0.7601 - accuracy: 0.8673 - loss: 0.4373 - val_AUC: 0.8771 - val_Precision: 0.9728 - val_Recall: 0.7299 - val_accuracy: 0.8696 - val_loss: 0.4206 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8893 - Precision: 0.9300 - Recall: 0.7601 - accuracy: 0.8673 - loss: 0.4373 - val_AUC: 0.8771 - val_Precision: 0.9728 - val_Recall: 0.7299 - val_accuracy: 0.8696 - val_loss: 0.4206 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8880 - Precision: 0.9460 - Recall: 0.7586 - accuracy: 0.8728 - loss: 0.4288 - val_AUC: 0.8792 - val_Precision: 0.9366 - val_Recall: 0.7547 - val_accuracy: 0.8670 - val_loss: 0.4152 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8880 - Precision: 0.9460 - Recall: 0.7586 - accuracy: 0.8728 - loss: 0.4288 - val_AUC: 0.8792 - val_Precision: 0.9366 - val_Recall: 0.7547 - val_accuracy: 0.8670 - val_loss: 0.4152 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8864 - Precision: 0.9419 - Recall: 0.7616 - accuracy: 0.8725 - loss: 0.4280 - val_AUC: 0.8771 - val_Precision: 0.9691 - val_Recall: 0.7314 - val_accuracy: 0.8689 - val_loss: 0.4162 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8864 - Precision: 0.9419 - Recall: 0.7616 - accuracy: 0.8725 - loss: 0.4280 - val_AUC: 0.8771 - val_Precision: 0.9691 - val_Recall: 0.7314 - val_accuracy: 0.8689 - val_loss: 0.4162 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8890 - Precision: 0.9415 - Recall: 0.7619 - accuracy: 0.8725 - loss: 0.4243 - val_AUC: 0.8758 - val_Precision: 0.9510 - val_Recall: 0.7372 - val_accuracy: 0.8650 - val_loss: 0.4154 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8890 - Precision: 0.9415 - Recall: 0.7619 - accuracy: 0.8725 - loss: 0.4243 - val_AUC: 0.8758 - val_Precision: 0.9510 - val_Recall: 0.7372 - val_accuracy: 0.8650 - val_loss: 0.4154 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8919 - Precision: 0.9476 - Recall: 0.7623 - accuracy: 0.8750 - loss: 0.4138 - val_AUC: 0.8675 - val_Precision: 0.9648 - val_Recall: 0.7212 - val_accuracy: 0.8630 - val_loss: 0.4245 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8919 - Precision: 0.9476 - Recall: 0.7623 - accuracy: 0.8750 - loss: 0.4138 - val_AUC: 0.8675 - val_Precision: 0.9648 - val_Recall: 0.7212 - val_accuracy: 0.8630 - val_loss: 0.4245 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8817 - Precision: 0.9460 - Recall: 0.7590 - accuracy: 0.8730 - loss: 0.4168 - val_AUC: 0.8749 - val_Precision: 0.9647 - val_Recall: 0.7182 - val_accuracy: 0.8617 - val_loss: 0.4162 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8817 - Precision: 0.9460 - Recall: 0.7590 - accuracy: 0.8730 - loss: 0.4168 - val_AUC: 0.8749 - val_Precision: 0.9647 - val_Recall: 0.7182 - val_accuracy: 0.8617 - val_loss: 0.4162 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8803 - Precision: 0.9515 - Recall: 0.7550 - accuracy: 0.8733 - loss: 0.4195 - val_AUC: 0.8800 - val_Precision: 0.9620 - val_Recall: 0.7401 - val_accuracy: 0.8702 - val_loss: 0.4061 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8803 - Precision: 0.9515 - Recall: 0.7550 - accuracy: 0.8733 - loss: 0.4195 - val_AUC: 0.8800 - val_Precision: 0.9620 - val_Recall: 0.7401 - val_accuracy: 0.8702 - val_loss: 0.4061 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8869 - Precision: 0.9476 - Recall: 0.7623 - accuracy: 0.8750 - loss: 0.4126 - val_AUC: 0.8666 - val_Precision: 0.9548 - val_Recall: 0.7095 - val_accuracy: 0.8545 - val_loss: 0.4271 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8869 - Precision: 0.9476 - Recall: 0.7623 - accuracy: 0.8750 - loss: 0.4126 - val_AUC: 0.8666 - val_Precision: 0.9548 - val_Recall: 0.7095 - val_accuracy: 0.8545 - val_loss: 0.4271 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8829 - Precision: 0.9604 - Recall: 0.7572 - accuracy: 0.8776 - loss: 0.4084 - val_AUC: 0.8802 - val_Precision: 0.9586 - val_Recall: 0.7431 - val_accuracy: 0.8702 - val_loss: 0.4075 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8829 - Precision: 0.9604 - Recall: 0.7572 - accuracy: 0.8776 - loss: 0.4084 - val_AUC: 0.8802 - val_Precision: 0.9586 - val_Recall: 0.7431 - val_accuracy: 0.8702 - val_loss: 0.4075 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8928 - Precision: 0.9523 - Recall: 0.7616 - accuracy: 0.8765 - loss: 0.3989 - val_AUC: 0.8754 - val_Precision: 0.9335 - val_Recall: 0.7577 - val_accuracy: 0.8670 - val_loss: 0.4005 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8928 - Precision: 0.9523 - Recall: 0.7616 - accuracy: 0.8765 - loss: 0.3989 - val_AUC: 0.8754 - val_Precision: 0.9335 - val_Recall: 0.7577 - val_accuracy: 0.8670 - val_loss: 0.4005 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8869 - Precision: 0.9530 - Recall: 0.7667 - accuracy: 0.8789 - loss: 0.4009 - val_AUC: 0.8787 - val_Precision: 0.9693 - val_Recall: 0.7372 - val_accuracy: 0.8716 - val_loss: 0.3907 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8869 - Precision: 0.9530 - Recall: 0.7667 - accuracy: 0.8789 - loss: 0.4009 - val_AUC: 0.8787 - val_Precision: 0.9693 - val_Recall: 0.7372 - val_accuracy: 0.8716 - val_loss: 0.3907 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8896 - Precision: 0.9530 - Recall: 0.7579 - accuracy: 0.8751 - loss: 0.3979 - val_AUC: 0.8748 - val_Precision: 0.9713 - val_Recall: 0.7401 - val_accuracy: 0.8735 - val_loss: 0.3854 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8896 - Precision: 0.9530 - Recall: 0.7579 - accuracy: 0.8751 - loss: 0.3979 - val_AUC: 0.8748 - val_Precision: 0.9713 - val_Recall: 0.7401 - val_accuracy: 0.8735 - val_loss: 0.3854 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8876 - Precision: 0.9514 - Recall: 0.7619 - accuracy: 0.8763 - loss: 0.3985 - val_AUC: 0.8792 - val_Precision: 0.9618 - val_Recall: 0.7358 - val_accuracy: 0.8683 - val_loss: 0.3946 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8876 - Precision: 0.9514 - Recall: 0.7619 - accuracy: 0.8763 - loss: 0.3985 - val_AUC: 0.8792 - val_Precision: 0.9618 - val_Recall: 0.7358 - val_accuracy: 0.8683 - val_loss: 0.3946 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8935 - Precision: 0.9623 - Recall: 0.7685 - accuracy: 0.8832 - loss: 0.3871 - val_AUC: 0.8669 - val_Precision: 0.9600 - val_Recall: 0.7358 - val_accuracy: 0.8676 - val_loss: 0.3950 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8935 - Precision: 0.9623 - Recall: 0.7685 - accuracy: 0.8832 - loss: 0.3871 - val_AUC: 0.8669 - val_Precision: 0.9600 - val_Recall: 0.7358 - val_accuracy: 0.8676 - val_loss: 0.3950 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8873 - Precision: 0.9478 - Recall: 0.7590 - accuracy: 0.8737 - loss: 0.4007 - val_AUC: 0.8723 - val_Precision: 0.9766 - val_Recall: 0.7314 - val_accuracy: 0.8716 - val_loss: 0.3905 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8873 - Precision: 0.9478 - Recall: 0.7590 - accuracy: 0.8737 - loss: 0.4007 - val_AUC: 0.8723 - val_Precision: 0.9766 - val_Recall: 0.7314 - val_accuracy: 0.8716 - val_loss: 0.3905 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8864 - Precision: 0.9602 - Recall: 0.7619 - accuracy: 0.8796 - loss: 0.3927 - val_AUC: 0.8820 - val_Precision: 0.9883 - val_Recall: 0.7387 - val_accuracy: 0.8788 - val_loss: 0.3786 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8864 - Precision: 0.9602 - Recall: 0.7619 - accuracy: 0.8796 - loss: 0.3927 - val_AUC: 0.8820 - val_Precision: 0.9883 - val_Recall: 0.7387 - val_accuracy: 0.8788 - val_loss: 0.3786 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8858 - Precision: 0.9595 - Recall: 0.7652 - accuracy: 0.8807 - loss: 0.3904 - val_AUC: 0.8707 - val_Precision: 0.9728 - val_Recall: 0.7314 - val_accuracy: 0.8702 - val_loss: 0.3834 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8858 - Precision: 0.9595 - Recall: 0.7652 - accuracy: 0.8807 - loss: 0.3904 - val_AUC: 0.8707 - val_Precision: 0.9728 - val_Recall: 0.7314 - val_accuracy: 0.8702 - val_loss: 0.3834 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8891 - Precision: 0.9596 - Recall: 0.7671 - accuracy: 0.8815 - loss: 0.3855 - val_AUC: 0.8815 - val_Precision: 0.9503 - val_Recall: 0.7533 - val_accuracy: 0.8716 - val_loss: 0.3796 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8891 - Precision: 0.9596 - Recall: 0.7671 - accuracy: 0.8815 - loss: 0.3855 - val_AUC: 0.8815 - val_Precision: 0.9503 - val_Recall: 0.7533 - val_accuracy: 0.8716 - val_loss: 0.3796 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8878 - Precision: 0.9569 - Recall: 0.7656 - accuracy: 0.8799 - loss: 0.3850 - val_AUC: 0.8755 - val_Precision: 0.9644 - val_Recall: 0.7518 - val_accuracy: 0.8761 - val_loss: 0.3793 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8878 - Precision: 0.9569 - Recall: 0.7656 - accuracy: 0.8799 - loss: 0.3850 - val_AUC: 0.8755 - val_Precision: 0.9644 - val_Recall: 0.7518 - val_accuracy: 0.8761 - val_loss: 0.3793 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8930 - Precision: 0.9640 - Recall: 0.7660 - accuracy: 0.8827 - loss: 0.3787 - val_AUC: 0.8744 - val_Precision: 0.9903 - val_Recall: 0.7431 - val_accuracy: 0.8814 - val_loss: 0.3735 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8930 - Precision: 0.9640 - Recall: 0.7660 - accuracy: 0.8827 - loss: 0.3787 - val_AUC: 0.8744 - val_Precision: 0.9903 - val_Recall: 0.7431 - val_accuracy: 0.8814 - val_loss: 0.3735 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8875 - Precision: 0.9608 - Recall: 0.7645 - accuracy: 0.8809 - loss: 0.3863 - val_AUC: 0.8781 - val_Precision: 0.9551 - val_Recall: 0.7460 - val_accuracy: 0.8702 - val_loss: 0.3825 - learning_rate: 5.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8875 - Precision: 0.9608 - Recall: 0.7645 - accuracy: 0.8809 - loss: 0.3863 - val_AUC: 0.8781 - val_Precision: 0.9551 - val_Recall: 0.7460 - val_accuracy: 0.8702 - val_loss: 0.3825 - learning_rate: 5.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8855 - Precision: 0.9583 - Recall: 0.7667 - accuracy: 0.8809 - loss: 0.3871 - val_AUC: 0.8822 - val_Precision: 0.9589 - val_Recall: 0.7489 - val_accuracy: 0.8729 - val_loss: 0.3822 - learning_rate: 5.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8855 - Precision: 0.9583 - Recall: 0.7667 - accuracy: 0.8809 - loss: 0.3871 - val_AUC: 0.8822 - val_Precision: 0.9589 - val_Recall: 0.7489 - val_accuracy: 0.8729 - val_loss: 0.3822 - learning_rate: 5.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8947 - Precision: 0.9596 - Recall: 0.7660 - accuracy: 0.8810 - loss: 0.3821 - val_AUC: 0.8741 - val_Precision: 0.9864 - val_Recall: 0.7401 - val_accuracy: 0.8788 - val_loss: 0.3756 - learning_rate: 5.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8947 - Precision: 0.9596 - Recall: 0.7660 - accuracy: 0.8810 - loss: 0.3821 - val_AUC: 0.8741 - val_Precision: 0.9864 - val_Recall: 0.7401 - val_accuracy: 0.8788 - val_loss: 0.3756 - learning_rate: 5.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8948 - Precision: 0.9554 - Recall: 0.7696 - accuracy: 0.8810 - loss: 0.3816 - val_AUC: 0.8703 - val_Precision: 0.9903 - val_Recall: 0.7416 - val_accuracy: 0.8807 - val_loss: 0.3781 - learning_rate: 5.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8948 - Precision: 0.9554 - Recall: 0.7696 - accuracy: 0.8810 - loss: 0.3816 - val_AUC: 0.8703 - val_Precision: 0.9903 - val_Recall: 0.7416 - val_accuracy: 0.8807 - val_loss: 0.3781 - learning_rate: 5.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8897 - Precision: 0.9645 - Recall: 0.7663 - accuracy: 0.8830 - loss: 0.3753 - val_AUC: 0.8770 - val_Precision: 0.9881 - val_Recall: 0.7285 - val_accuracy: 0.8742 - val_loss: 0.3793 - learning_rate: 5.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8897 - Precision: 0.9645 - Recall: 0.7663 - accuracy: 0.8830 - loss: 0.3753 - val_AUC: 0.8770 - val_Precision: 0.9881 - val_Recall: 0.7285 - val_accuracy: 0.8742 - val_loss: 0.3793 - learning_rate: 5.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9603 - Recall: 0.7634 - accuracy: 0.8802 - loss: 0.3829 - val_AUC: 0.8767 - val_Precision: 0.9766 - val_Recall: 0.7299 - val_accuracy: 0.8709 - val_loss: 0.3809 - learning_rate: 5.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9603 - Recall: 0.7634 - accuracy: 0.8802 - loss: 0.3829 - val_AUC: 0.8767 - val_Precision: 0.9766 - val_Recall: 0.7299 - val_accuracy: 0.8709 - val_loss: 0.3809 - learning_rate: 5.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8881 - Precision: 0.9651 - Recall: 0.7608 - accuracy: 0.8809 - loss: 0.3801 - val_AUC: 0.8734 - val_Precision: 0.9698 - val_Recall: 0.7489 - val_accuracy: 0.8768 - val_loss: 0.3675 - learning_rate: 5.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8881 - Precision: 0.9651 - Recall: 0.7608 - accuracy: 0.8809 - loss: 0.3801 - val_AUC: 0.8734 - val_Precision: 0.9698 - val_Recall: 0.7489 - val_accuracy: 0.8768 - val_loss: 0.3675 - learning_rate: 5.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8939 - Precision: 0.9625 - Recall: 0.7630 - accuracy: 0.8809 - loss: 0.3740 - val_AUC: 0.8733 - val_Precision: 0.9749 - val_Recall: 0.7372 - val_accuracy: 0.8735 - val_loss: 0.3742 - learning_rate: 5.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8939 - Precision: 0.9625 - Recall: 0.7630 - accuracy: 0.8809 - loss: 0.3740 - val_AUC: 0.8733 - val_Precision: 0.9749 - val_Recall: 0.7372 - val_accuracy: 0.8735 - val_loss: 0.3742 - learning_rate: 5.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8892 - Precision: 0.9545 - Recall: 0.7612 - accuracy: 0.8771 - loss: 0.3841 - val_AUC: 0.8717 - val_Precision: 0.9787 - val_Recall: 0.7372 - val_accuracy: 0.8748 - val_loss: 0.3732 - learning_rate: 5.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8892 - Precision: 0.9545 - Recall: 0.7612 - accuracy: 0.8771 - loss: 0.3841 - val_AUC: 0.8717 - val_Precision: 0.9787 - val_Recall: 0.7372 - val_accuracy: 0.8748 - val_loss: 0.3732 - learning_rate: 5.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8947 - Precision: 0.9563 - Recall: 0.7700 - accuracy: 0.8815 - loss: 0.3779 - val_AUC: 0.8786 - val_Precision: 0.9555 - val_Recall: 0.7518 - val_accuracy: 0.8729 - val_loss: 0.3821 - learning_rate: 5.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8947 - Precision: 0.9563 - Recall: 0.7700 - accuracy: 0.8815 - loss: 0.3779 - val_AUC: 0.8786 - val_Precision: 0.9555 - val_Recall: 0.7518 - val_accuracy: 0.8729 - val_loss: 0.3821 - learning_rate: 5.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8944 - Precision: 0.9655 - Recall: 0.7696 - accuracy: 0.8848 - loss: 0.3704 - val_AUC: 0.8794 - val_Precision: 0.9662 - val_Recall: 0.7518 - val_accuracy: 0.8768 - val_loss: 0.3750 - learning_rate: 5.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8944 - Precision: 0.9655 - Recall: 0.7696 - accuracy: 0.8848 - loss: 0.3704 - val_AUC: 0.8794 - val_Precision: 0.9662 - val_Recall: 0.7518 - val_accuracy: 0.8768 - val_loss: 0.3750 - learning_rate: 5.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8896 - Precision: 0.9522 - Recall: 0.7605 - accuracy: 0.8760 - loss: 0.3842 - val_AUC: 0.8776 - val_Precision: 0.9980 - val_Recall: 0.7285 - val_accuracy: 0.8775 - val_loss: 0.3725 - learning_rate: 5.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8896 - Precision: 0.9522 - Recall: 0.7605 - accuracy: 0.8760 - loss: 0.3842 - val_AUC: 0.8776 - val_Precision: 0.9980 - val_Recall: 0.7285 - val_accuracy: 0.8775 - val_loss: 0.3725 - learning_rate: 5.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8980 - Precision: 0.9744 - Recall: 0.7667 - accuracy: 0.8868 - loss: 0.3675 - val_AUC: 0.8780 - val_Precision: 0.9922 - val_Recall: 0.7416 - val_accuracy: 0.8814 - val_loss: 0.3635 - learning_rate: 5.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8980 - Precision: 0.9744 - Recall: 0.7667 - accuracy: 0.8868 - loss: 0.3675 - val_AUC: 0.8780 - val_Precision: 0.9922 - val_Recall: 0.7416 - val_accuracy: 0.8814 - val_loss: 0.3635 - learning_rate: 5.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8943 - Precision: 0.9708 - Recall: 0.7674 - accuracy: 0.8858 - loss: 0.3680 - val_AUC: 0.8754 - val_Precision: 0.9470 - val_Recall: 0.7562 - val_accuracy: 0.8716 - val_loss: 0.3675 - learning_rate: 5.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8943 - Precision: 0.9708 - Recall: 0.7674 - accuracy: 0.8858 - loss: 0.3680 - val_AUC: 0.8754 - val_Precision: 0.9470 - val_Recall: 0.7562 - val_accuracy: 0.8716 - val_loss: 0.3675 - learning_rate: 5.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8925 - Precision: 0.9708 - Recall: 0.7685 - accuracy: 0.8863 - loss: 0.3639 - val_AUC: 0.8766 - val_Precision: 0.9788 - val_Recall: 0.7401 - val_accuracy: 0.8761 - val_loss: 0.3669 - learning_rate: 5.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8925 - Precision: 0.9708 - Recall: 0.7685 - accuracy: 0.8863 - loss: 0.3639 - val_AUC: 0.8766 - val_Precision: 0.9788 - val_Recall: 0.7401 - val_accuracy: 0.8761 - val_loss: 0.3669 - learning_rate: 5.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8949 - Precision: 0.9685 - Recall: 0.7682 - accuracy: 0.8853 - loss: 0.3679 - val_AUC: 0.8775 - val_Precision: 0.9661 - val_Recall: 0.7489 - val_accuracy: 0.8755 - val_loss: 0.3710 - learning_rate: 5.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8949 - Precision: 0.9685 - Recall: 0.7682 - accuracy: 0.8853 - loss: 0.3679 - val_AUC: 0.8775 - val_Precision: 0.9661 - val_Recall: 0.7489 - val_accuracy: 0.8755 - val_loss: 0.3710 - learning_rate: 5.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8941 - Precision: 0.9596 - Recall: 0.7667 - accuracy: 0.8814 - loss: 0.3761 - val_AUC: 0.8759 - val_Precision: 0.9771 - val_Recall: 0.7474 - val_accuracy: 0.8788 - val_loss: 0.3704 - learning_rate: 5.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8941 - Precision: 0.9596 - Recall: 0.7667 - accuracy: 0.8814 - loss: 0.3761 - val_AUC: 0.8759 - val_Precision: 0.9771 - val_Recall: 0.7474 - val_accuracy: 0.8788 - val_loss: 0.3704 - learning_rate: 5.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8949 - Precision: 0.9672 - Recall: 0.7682 - accuracy: 0.8848 - loss: 0.3678 - val_AUC: 0.8738 - val_Precision: 0.9537 - val_Recall: 0.7518 - val_accuracy: 0.8722 - val_loss: 0.3728 - learning_rate: 5.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8949 - Precision: 0.9672 - Recall: 0.7682 - accuracy: 0.8848 - loss: 0.3678 - val_AUC: 0.8738 - val_Precision: 0.9537 - val_Recall: 0.7518 - val_accuracy: 0.8722 - val_loss: 0.3728 - learning_rate: 5.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8902 - Precision: 0.9573 - Recall: 0.7726 - accuracy: 0.8830 - loss: 0.3745 - val_AUC: 0.8700 - val_Precision: 0.9712 - val_Recall: 0.7387 - val_accuracy: 0.8729 - val_loss: 0.3708 - learning_rate: 5.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8902 - Precision: 0.9573 - Recall: 0.7726 - accuracy: 0.8830 - loss: 0.3745 - val_AUC: 0.8700 - val_Precision: 0.9712 - val_Recall: 0.7387 - val_accuracy: 0.8729 - val_loss: 0.3708 - learning_rate: 5.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m89/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8874 - Precision: 0.9676 - Recall: 0.7548 - accuracy: 0.8771 - loss: 0.3803\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8938 - Precision: 0.9684 - Recall: 0.7645 - accuracy: 0.8837 - loss: 0.3670 - val_AUC: 0.8742 - val_Precision: 0.9864 - val_Recall: 0.7416 - val_accuracy: 0.8794 - val_loss: 0.3642 - learning_rate: 5.0000e-04\n",
      "Epoch 66/150\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8938 - Precision: 0.9684 - Recall: 0.7645 - accuracy: 0.8837 - loss: 0.3670 - val_AUC: 0.8742 - val_Precision: 0.9864 - val_Recall: 0.7416 - val_accuracy: 0.8794 - val_loss: 0.3642 - learning_rate: 5.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - AUC: 0.8995 - Precision: 0.9782 - Recall: 0.7737 - accuracy: 0.8912 - loss: 0.3520 - val_AUC: 0.8742 - val_Precision: 0.9698 - val_Recall: 0.7489 - val_accuracy: 0.8768 - val_loss: 0.3620 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - AUC: 0.8995 - Precision: 0.9782 - Recall: 0.7737 - accuracy: 0.8912 - loss: 0.3520 - val_AUC: 0.8742 - val_Precision: 0.9698 - val_Recall: 0.7489 - val_accuracy: 0.8768 - val_loss: 0.3620 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9019 - Precision: 0.9757 - Recall: 0.7792 - accuracy: 0.8927 - loss: 0.3462 - val_AUC: 0.8774 - val_Precision: 0.9827 - val_Recall: 0.7474 - val_accuracy: 0.8807 - val_loss: 0.3552 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9019 - Precision: 0.9757 - Recall: 0.7792 - accuracy: 0.8927 - loss: 0.3462 - val_AUC: 0.8774 - val_Precision: 0.9827 - val_Recall: 0.7474 - val_accuracy: 0.8807 - val_loss: 0.3552 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9064 - Precision: 0.9747 - Recall: 0.7781 - accuracy: 0.8919 - loss: 0.3410 - val_AUC: 0.8761 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3559 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9064 - Precision: 0.9747 - Recall: 0.7781 - accuracy: 0.8919 - loss: 0.3410 - val_AUC: 0.8761 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3559 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9065 - Precision: 0.9784 - Recall: 0.7814 - accuracy: 0.8946 - loss: 0.3345 - val_AUC: 0.8749 - val_Precision: 0.9753 - val_Recall: 0.7489 - val_accuracy: 0.8788 - val_loss: 0.3569 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9065 - Precision: 0.9784 - Recall: 0.7814 - accuracy: 0.8946 - loss: 0.3345 - val_AUC: 0.8749 - val_Precision: 0.9753 - val_Recall: 0.7489 - val_accuracy: 0.8788 - val_loss: 0.3569 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9093 - Precision: 0.9775 - Recall: 0.7803 - accuracy: 0.8938 - loss: 0.3330 - val_AUC: 0.8727 - val_Precision: 0.9734 - val_Recall: 0.7489 - val_accuracy: 0.8781 - val_loss: 0.3567 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9093 - Precision: 0.9775 - Recall: 0.7803 - accuracy: 0.8938 - loss: 0.3330 - val_AUC: 0.8727 - val_Precision: 0.9734 - val_Recall: 0.7489 - val_accuracy: 0.8781 - val_loss: 0.3567 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9058 - Precision: 0.9779 - Recall: 0.7795 - accuracy: 0.8937 - loss: 0.3331 - val_AUC: 0.8726 - val_Precision: 0.9717 - val_Recall: 0.7518 - val_accuracy: 0.8788 - val_loss: 0.3556 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9058 - Precision: 0.9779 - Recall: 0.7795 - accuracy: 0.8937 - loss: 0.3331 - val_AUC: 0.8726 - val_Precision: 0.9717 - val_Recall: 0.7518 - val_accuracy: 0.8788 - val_loss: 0.3556 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9039 - Precision: 0.9735 - Recall: 0.7825 - accuracy: 0.8933 - loss: 0.3318 - val_AUC: 0.8735 - val_Precision: 0.9771 - val_Recall: 0.7474 - val_accuracy: 0.8788 - val_loss: 0.3519 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9039 - Precision: 0.9735 - Recall: 0.7825 - accuracy: 0.8933 - loss: 0.3318 - val_AUC: 0.8735 - val_Precision: 0.9771 - val_Recall: 0.7474 - val_accuracy: 0.8788 - val_loss: 0.3519 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9052 - Precision: 0.9761 - Recall: 0.7788 - accuracy: 0.8927 - loss: 0.3324 - val_AUC: 0.8736 - val_Precision: 0.9772 - val_Recall: 0.7504 - val_accuracy: 0.8801 - val_loss: 0.3537 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9052 - Precision: 0.9761 - Recall: 0.7788 - accuracy: 0.8927 - loss: 0.3324 - val_AUC: 0.8736 - val_Precision: 0.9772 - val_Recall: 0.7504 - val_accuracy: 0.8801 - val_loss: 0.3537 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9086 - Precision: 0.9811 - Recall: 0.7799 - accuracy: 0.8950 - loss: 0.3256 - val_AUC: 0.8726 - val_Precision: 0.9754 - val_Recall: 0.7518 - val_accuracy: 0.8801 - val_loss: 0.3516 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9086 - Precision: 0.9811 - Recall: 0.7799 - accuracy: 0.8950 - loss: 0.3256 - val_AUC: 0.8726 - val_Precision: 0.9754 - val_Recall: 0.7518 - val_accuracy: 0.8801 - val_loss: 0.3516 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9138 - Precision: 0.9781 - Recall: 0.7872 - accuracy: 0.8971 - loss: 0.3201 - val_AUC: 0.8725 - val_Precision: 0.9735 - val_Recall: 0.7518 - val_accuracy: 0.8794 - val_loss: 0.3522 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9138 - Precision: 0.9781 - Recall: 0.7872 - accuracy: 0.8971 - loss: 0.3201 - val_AUC: 0.8725 - val_Precision: 0.9735 - val_Recall: 0.7518 - val_accuracy: 0.8794 - val_loss: 0.3522 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9179 - Precision: 0.9776 - Recall: 0.7861 - accuracy: 0.8964 - loss: 0.3180 - val_AUC: 0.8702 - val_Precision: 0.9734 - val_Recall: 0.7489 - val_accuracy: 0.8781 - val_loss: 0.3552 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9179 - Precision: 0.9776 - Recall: 0.7861 - accuracy: 0.8964 - loss: 0.3180 - val_AUC: 0.8702 - val_Precision: 0.9734 - val_Recall: 0.7489 - val_accuracy: 0.8781 - val_loss: 0.3552 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9143 - Precision: 0.9763 - Recall: 0.7850 - accuracy: 0.8955 - loss: 0.3217 - val_AUC: 0.8697 - val_Precision: 0.9698 - val_Recall: 0.7504 - val_accuracy: 0.8775 - val_loss: 0.3502 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9143 - Precision: 0.9763 - Recall: 0.7850 - accuracy: 0.8955 - loss: 0.3217 - val_AUC: 0.8697 - val_Precision: 0.9698 - val_Recall: 0.7504 - val_accuracy: 0.8775 - val_loss: 0.3502 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9149 - Precision: 0.9803 - Recall: 0.7843 - accuracy: 0.8966 - loss: 0.3209 - val_AUC: 0.8707 - val_Precision: 0.9699 - val_Recall: 0.7533 - val_accuracy: 0.8788 - val_loss: 0.3547 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9149 - Precision: 0.9803 - Recall: 0.7843 - accuracy: 0.8966 - loss: 0.3209 - val_AUC: 0.8707 - val_Precision: 0.9699 - val_Recall: 0.7533 - val_accuracy: 0.8788 - val_loss: 0.3547 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9136 - Precision: 0.9807 - Recall: 0.7847 - accuracy: 0.8969 - loss: 0.3182 - val_AUC: 0.8705 - val_Precision: 0.9681 - val_Recall: 0.7533 - val_accuracy: 0.8781 - val_loss: 0.3525 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9136 - Precision: 0.9807 - Recall: 0.7847 - accuracy: 0.8969 - loss: 0.3182 - val_AUC: 0.8705 - val_Precision: 0.9681 - val_Recall: 0.7533 - val_accuracy: 0.8781 - val_loss: 0.3525 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9119 - Precision: 0.9745 - Recall: 0.7865 - accuracy: 0.8955 - loss: 0.3233 - val_AUC: 0.8700 - val_Precision: 0.9827 - val_Recall: 0.7460 - val_accuracy: 0.8801 - val_loss: 0.3477 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9119 - Precision: 0.9745 - Recall: 0.7865 - accuracy: 0.8955 - loss: 0.3233 - val_AUC: 0.8700 - val_Precision: 0.9827 - val_Recall: 0.7460 - val_accuracy: 0.8801 - val_loss: 0.3477 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9196 - Precision: 0.9795 - Recall: 0.7891 - accuracy: 0.8984 - loss: 0.3145 - val_AUC: 0.8697 - val_Precision: 0.9754 - val_Recall: 0.7518 - val_accuracy: 0.8801 - val_loss: 0.3517 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9196 - Precision: 0.9795 - Recall: 0.7891 - accuracy: 0.8984 - loss: 0.3145 - val_AUC: 0.8697 - val_Precision: 0.9754 - val_Recall: 0.7518 - val_accuracy: 0.8801 - val_loss: 0.3517 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9141 - Precision: 0.9741 - Recall: 0.7858 - accuracy: 0.8950 - loss: 0.3184 - val_AUC: 0.8719 - val_Precision: 0.9698 - val_Recall: 0.7489 - val_accuracy: 0.8768 - val_loss: 0.3563 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9141 - Precision: 0.9741 - Recall: 0.7858 - accuracy: 0.8950 - loss: 0.3184 - val_AUC: 0.8719 - val_Precision: 0.9698 - val_Recall: 0.7489 - val_accuracy: 0.8768 - val_loss: 0.3563 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9150 - Precision: 0.9768 - Recall: 0.7865 - accuracy: 0.8963 - loss: 0.3186 - val_AUC: 0.8718 - val_Precision: 0.9644 - val_Recall: 0.7504 - val_accuracy: 0.8755 - val_loss: 0.3656 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9150 - Precision: 0.9768 - Recall: 0.7865 - accuracy: 0.8963 - loss: 0.3186 - val_AUC: 0.8718 - val_Precision: 0.9644 - val_Recall: 0.7504 - val_accuracy: 0.8755 - val_loss: 0.3656 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9149 - Precision: 0.9781 - Recall: 0.7847 - accuracy: 0.8960 - loss: 0.3176 - val_AUC: 0.8707 - val_Precision: 0.9590 - val_Recall: 0.7504 - val_accuracy: 0.8735 - val_loss: 0.3635 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9149 - Precision: 0.9781 - Recall: 0.7847 - accuracy: 0.8960 - loss: 0.3176 - val_AUC: 0.8707 - val_Precision: 0.9590 - val_Recall: 0.7504 - val_accuracy: 0.8735 - val_loss: 0.3635 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9199 - Precision: 0.9763 - Recall: 0.7872 - accuracy: 0.8964 - loss: 0.3129 - val_AUC: 0.8736 - val_Precision: 0.9733 - val_Recall: 0.7460 - val_accuracy: 0.8768 - val_loss: 0.3580 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9199 - Precision: 0.9763 - Recall: 0.7872 - accuracy: 0.8964 - loss: 0.3129 - val_AUC: 0.8736 - val_Precision: 0.9733 - val_Recall: 0.7460 - val_accuracy: 0.8768 - val_loss: 0.3580 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9131 - Precision: 0.9777 - Recall: 0.7872 - accuracy: 0.8969 - loss: 0.3188 - val_AUC: 0.8720 - val_Precision: 0.9771 - val_Recall: 0.7460 - val_accuracy: 0.8781 - val_loss: 0.3571 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9131 - Precision: 0.9777 - Recall: 0.7872 - accuracy: 0.8969 - loss: 0.3188 - val_AUC: 0.8720 - val_Precision: 0.9771 - val_Recall: 0.7460 - val_accuracy: 0.8781 - val_loss: 0.3571 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m91/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9130 - Precision: 0.9830 - Recall: 0.7763 - accuracy: 0.8946 - loss: 0.3195\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9185 - Precision: 0.9831 - Recall: 0.7887 - accuracy: 0.8996 - loss: 0.3110 - val_AUC: 0.8725 - val_Precision: 0.9625 - val_Recall: 0.7504 - val_accuracy: 0.8748 - val_loss: 0.3646 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9185 - Precision: 0.9831 - Recall: 0.7887 - accuracy: 0.8996 - loss: 0.3110 - val_AUC: 0.8725 - val_Precision: 0.9625 - val_Recall: 0.7504 - val_accuracy: 0.8748 - val_loss: 0.3646 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9198 - Precision: 0.9734 - Recall: 0.7935 - accuracy: 0.8981 - loss: 0.3099 - val_AUC: 0.8721 - val_Precision: 0.9716 - val_Recall: 0.7504 - val_accuracy: 0.8781 - val_loss: 0.3614 - learning_rate: 2.0000e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9198 - Precision: 0.9734 - Recall: 0.7935 - accuracy: 0.8981 - loss: 0.3099 - val_AUC: 0.8721 - val_Precision: 0.9716 - val_Recall: 0.7504 - val_accuracy: 0.8781 - val_loss: 0.3614 - learning_rate: 2.0000e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9224 - Precision: 0.9813 - Recall: 0.7913 - accuracy: 0.9000 - loss: 0.3064 - val_AUC: 0.8718 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3581 - learning_rate: 2.0000e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9224 - Precision: 0.9813 - Recall: 0.7913 - accuracy: 0.9000 - loss: 0.3064 - val_AUC: 0.8718 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3581 - learning_rate: 2.0000e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9264 - Precision: 0.9832 - Recall: 0.7924 - accuracy: 0.9012 - loss: 0.3006 - val_AUC: 0.8718 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3598 - learning_rate: 2.0000e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9264 - Precision: 0.9832 - Recall: 0.7924 - accuracy: 0.9012 - loss: 0.3006 - val_AUC: 0.8718 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3598 - learning_rate: 2.0000e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9224 - Precision: 0.9832 - Recall: 0.7924 - accuracy: 0.9012 - loss: 0.3033 - val_AUC: 0.8710 - val_Precision: 0.9715 - val_Recall: 0.7474 - val_accuracy: 0.8768 - val_loss: 0.3621 - learning_rate: 2.0000e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9224 - Precision: 0.9832 - Recall: 0.7924 - accuracy: 0.9012 - loss: 0.3033 - val_AUC: 0.8710 - val_Precision: 0.9715 - val_Recall: 0.7474 - val_accuracy: 0.8768 - val_loss: 0.3621 - learning_rate: 2.0000e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9257 - Precision: 0.9845 - Recall: 0.7913 - accuracy: 0.9012 - loss: 0.3013 - val_AUC: 0.8705 - val_Precision: 0.9752 - val_Recall: 0.7474 - val_accuracy: 0.8781 - val_loss: 0.3614 - learning_rate: 2.0000e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9257 - Precision: 0.9845 - Recall: 0.7913 - accuracy: 0.9012 - loss: 0.3013 - val_AUC: 0.8705 - val_Precision: 0.9752 - val_Recall: 0.7474 - val_accuracy: 0.8781 - val_loss: 0.3614 - learning_rate: 2.0000e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9282 - Precision: 0.9814 - Recall: 0.7920 - accuracy: 0.9004 - loss: 0.3012 - val_AUC: 0.8708 - val_Precision: 0.9734 - val_Recall: 0.7474 - val_accuracy: 0.8775 - val_loss: 0.3626 - learning_rate: 2.0000e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9282 - Precision: 0.9814 - Recall: 0.7920 - accuracy: 0.9004 - loss: 0.3012 - val_AUC: 0.8708 - val_Precision: 0.9734 - val_Recall: 0.7474 - val_accuracy: 0.8775 - val_loss: 0.3626 - learning_rate: 2.0000e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m94/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9266 - Precision: 0.9723 - Recall: 0.7867 - accuracy: 0.8971 - loss: 0.3024\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9277 - Precision: 0.9805 - Recall: 0.7927 - accuracy: 0.9004 - loss: 0.2993 - val_AUC: 0.8711 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3637 - learning_rate: 2.0000e-05\n",
      "Epoch 95/150\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9277 - Precision: 0.9805 - Recall: 0.7927 - accuracy: 0.9004 - loss: 0.2993 - val_AUC: 0.8711 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3637 - learning_rate: 2.0000e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9289 - Precision: 0.9805 - Recall: 0.7931 - accuracy: 0.9005 - loss: 0.3002 - val_AUC: 0.8714 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3641 - learning_rate: 4.0000e-06\n",
      "Epoch 96/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9289 - Precision: 0.9805 - Recall: 0.7931 - accuracy: 0.9005 - loss: 0.3002 - val_AUC: 0.8714 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3641 - learning_rate: 4.0000e-06\n",
      "Epoch 96/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9269 - Precision: 0.9828 - Recall: 0.7949 - accuracy: 0.9022 - loss: 0.2989 - val_AUC: 0.8711 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3635 - learning_rate: 4.0000e-06\n",
      "Epoch 97/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9269 - Precision: 0.9828 - Recall: 0.7949 - accuracy: 0.9022 - loss: 0.2989 - val_AUC: 0.8711 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3635 - learning_rate: 4.0000e-06\n",
      "Epoch 97/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9299 - Precision: 0.9810 - Recall: 0.7946 - accuracy: 0.9014 - loss: 0.2972 - val_AUC: 0.8714 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3639 - learning_rate: 4.0000e-06\n",
      "Epoch 98/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9299 - Precision: 0.9810 - Recall: 0.7946 - accuracy: 0.9014 - loss: 0.2972 - val_AUC: 0.8714 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3639 - learning_rate: 4.0000e-06\n",
      "Epoch 98/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9270 - Precision: 0.9818 - Recall: 0.7898 - accuracy: 0.8996 - loss: 0.3011 - val_AUC: 0.8712 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3640 - learning_rate: 4.0000e-06\n",
      "Epoch 99/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9270 - Precision: 0.9818 - Recall: 0.7898 - accuracy: 0.8996 - loss: 0.3011 - val_AUC: 0.8712 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3640 - learning_rate: 4.0000e-06\n",
      "Epoch 99/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9292 - Precision: 0.9827 - Recall: 0.7916 - accuracy: 0.9007 - loss: 0.2973 - val_AUC: 0.8716 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3645 - learning_rate: 4.0000e-06\n",
      "Epoch 100/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9292 - Precision: 0.9827 - Recall: 0.7916 - accuracy: 0.9007 - loss: 0.2973 - val_AUC: 0.8716 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3645 - learning_rate: 4.0000e-06\n",
      "Epoch 100/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9327 - Precision: 0.9810 - Recall: 0.7949 - accuracy: 0.9015 - loss: 0.2935 - val_AUC: 0.8711 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3652 - learning_rate: 4.0000e-06\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9327 - Precision: 0.9810 - Recall: 0.7949 - accuracy: 0.9015 - loss: 0.2935 - val_AUC: 0.8711 - val_Precision: 0.9735 - val_Recall: 0.7504 - val_accuracy: 0.8788 - val_loss: 0.3652 - learning_rate: 4.0000e-06\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 88.21%\n",
      "Precision: 98.76%\n",
      "Recall: 74.56%\n",
      "AUC: 0.8759\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 88.21%\n",
      "Precision: 98.76%\n",
      "Recall: 74.56%\n",
      "AUC: 0.8759\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'auc_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 150\u001b[39m\n\u001b[32m    147\u001b[39m plt.legend()\n\u001b[32m    149\u001b[39m plt.subplot(\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m3\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mauc_1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label=\u001b[33m'\u001b[39m\u001b[33mTrain AUC\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    151\u001b[39m plt.plot(history.history[\u001b[33m'\u001b[39m\u001b[33mval_auc_1\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mVal AUC\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    152\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mModel AUC\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'auc_1'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"Sheets/cybersecurity_intrusion_data.csv\")\n",
    "data = data.drop('session_id', axis=1)\n",
    "\n",
    "# Enhanced Feature Engineering\n",
    "data['failed_ratio'] = data['failed_logins'] / (data['login_attempts'] + 1)\n",
    "data['data_rate'] = data['network_packet_size'] / (data['session_duration'] + 1)\n",
    "data['high_risk'] = ((data['ip_reputation_score'] < 0.4) & \n",
    "                     (data['unusual_time_access'] > 0.6)).astype(int)\n",
    "data['activity_score'] = (data['network_packet_size'] * data['login_attempts']) / \\\n",
    "                        (data['session_duration'] + 1)\n",
    "data['risk_score'] = (1 - data['ip_reputation_score']) * data['unusual_time_access']\n",
    "data['login_frequency'] = data['login_attempts'] / (data['session_duration'] + 1)\n",
    "data['packet_size_per_login'] = data['network_packet_size'] / (data['login_attempts'] + 1)\n",
    "data['risk_activity_ratio'] = data['risk_score'] * data['activity_score']\n",
    "\n",
    "# Interaction features\n",
    "data['high_risk_failed'] = data['high_risk'] * data['failed_ratio']\n",
    "data['risk_login_freq'] = data['risk_score'] * data['login_frequency']\n",
    "\n",
    "# Handle categorical features with improved encoding\n",
    "categorical_cols = ['protocol_type', 'encryption_used', 'browser_type']\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "encoded = encoder.fit_transform(data[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Combine all features\n",
    "data = pd.concat([data.drop(columns=categorical_cols).reset_index(drop=True),\n",
    "                 encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Replace infinities and normalize features\n",
    "data = data.replace([np.inf, -np.inf], np.nan)\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "X = data.drop('attack_detected', axis=1)\n",
    "y = data['attack_detected']\n",
    "\n",
    "# Split data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Advanced preprocessing pipeline\n",
    "scaler = StandardScaler()\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = power.fit_transform(X_train_scaled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = power.transform(X_test_scaled)\n",
    "\n",
    "# Compute class weights for balanced training\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Enhanced model architecture with residual-like connections\n",
    "model = Sequential([\n",
    "    # Input layer\n",
    "    Dense(512, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "          kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # First hidden layer\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Second hidden layer\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Third hidden layer\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Output layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile with optimized learning rate and metrics\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, \n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "\n",
    "# Advanced callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=7,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train with class weights and advanced parameters\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy, precision, recall, auc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history.history['auc_1'], label='Train AUC')\n",
    "plt.plot(history.history['val_auc_1'], label='Val AUC')\n",
    "plt.title('Model AUC')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate predictions and detailed classification report\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Attack', 'Attack']))\n",
    "\n",
    "# Plot enhanced confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Attack', 'Attack'],\n",
    "            yticklabels=['No Attack', 'Attack'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Save the improved model\n",
    "model.save(\"cybersecurity_intrusion_ann_model_v2.h5\")\n",
    "print(\"\\nImproved model saved as 'cybersecurity_intrusion_ann_model_v2.h5'\")\n",
    "\n",
    "# Print feature importance analysis\n",
    "feature_importance = np.abs(model.layers[0].get_weights()[0]).mean(axis=1)\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature')\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a41c92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Deep Singh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - AUC: 0.7113 - Precision: 0.6088 - Recall: 0.6669 - accuracy: 0.6598 - loss: 6.5199 - val_AUC: 0.7965 - val_Precision: 0.8048 - val_Recall: 0.4934 - val_accuracy: 0.7189 - val_loss: 5.8485 - learning_rate: 5.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - AUC: 0.7113 - Precision: 0.6088 - Recall: 0.6669 - accuracy: 0.6598 - loss: 6.5199 - val_AUC: 0.7965 - val_Precision: 0.8048 - val_Recall: 0.4934 - val_accuracy: 0.7189 - val_loss: 5.8485 - learning_rate: 5.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.7915 - Precision: 0.6965 - Recall: 0.7014 - accuracy: 0.7301 - loss: 5.2344 - val_AUC: 0.8194 - val_Precision: 0.9686 - val_Recall: 0.2248 - val_accuracy: 0.6488 - val_loss: 4.7347 - learning_rate: 5.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.7915 - Precision: 0.6965 - Recall: 0.7014 - accuracy: 0.7301 - loss: 5.2344 - val_AUC: 0.8194 - val_Precision: 0.9686 - val_Recall: 0.2248 - val_accuracy: 0.6488 - val_loss: 4.7347 - learning_rate: 5.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8213 - Precision: 0.7489 - Recall: 0.7003 - accuracy: 0.7613 - loss: 4.1906 - val_AUC: 0.8344 - val_Precision: 0.9914 - val_Recall: 0.3372 - val_accuracy: 0.7012 - val_loss: 3.8019 - learning_rate: 5.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8213 - Precision: 0.7489 - Recall: 0.7003 - accuracy: 0.7613 - loss: 4.1906 - val_AUC: 0.8344 - val_Precision: 0.9914 - val_Recall: 0.3372 - val_accuracy: 0.7012 - val_loss: 3.8019 - learning_rate: 5.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8373 - Precision: 0.7836 - Recall: 0.7080 - accuracy: 0.7822 - loss: 3.3567 - val_AUC: 0.8467 - val_Precision: 0.9935 - val_Recall: 0.4438 - val_accuracy: 0.7490 - val_loss: 3.0448 - learning_rate: 5.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8373 - Precision: 0.7836 - Recall: 0.7080 - accuracy: 0.7822 - loss: 3.3567 - val_AUC: 0.8467 - val_Precision: 0.9935 - val_Recall: 0.4438 - val_accuracy: 0.7490 - val_loss: 3.0448 - learning_rate: 5.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8558 - Precision: 0.8115 - Recall: 0.7359 - accuracy: 0.8057 - loss: 2.6890 - val_AUC: 0.8596 - val_Precision: 0.9949 - val_Recall: 0.5650 - val_accuracy: 0.8034 - val_loss: 2.4283 - learning_rate: 5.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8558 - Precision: 0.8115 - Recall: 0.7359 - accuracy: 0.8057 - loss: 2.6890 - val_AUC: 0.8596 - val_Precision: 0.9949 - val_Recall: 0.5650 - val_accuracy: 0.8034 - val_loss: 2.4283 - learning_rate: 5.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8624 - Precision: 0.8425 - Recall: 0.7359 - accuracy: 0.8206 - loss: 2.1754 - val_AUC: 0.8606 - val_Precision: 0.9953 - val_Recall: 0.6248 - val_accuracy: 0.8303 - val_loss: 1.9507 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8624 - Precision: 0.8425 - Recall: 0.7359 - accuracy: 0.8206 - loss: 2.1754 - val_AUC: 0.8606 - val_Precision: 0.9953 - val_Recall: 0.6248 - val_accuracy: 0.8303 - val_loss: 1.9507 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8716 - Precision: 0.8533 - Recall: 0.7425 - accuracy: 0.8280 - loss: 1.7693 - val_AUC: 0.8644 - val_Precision: 0.9910 - val_Recall: 0.6394 - val_accuracy: 0.8355 - val_loss: 1.6032 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8716 - Precision: 0.8533 - Recall: 0.7425 - accuracy: 0.8280 - loss: 1.7693 - val_AUC: 0.8644 - val_Precision: 0.9910 - val_Recall: 0.6394 - val_accuracy: 0.8355 - val_loss: 1.6032 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8743 - Precision: 0.8614 - Recall: 0.7480 - accuracy: 0.8337 - loss: 1.4660 - val_AUC: 0.8685 - val_Precision: 0.9930 - val_Recall: 0.6234 - val_accuracy: 0.8290 - val_loss: 1.3418 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8743 - Precision: 0.8614 - Recall: 0.7480 - accuracy: 0.8337 - loss: 1.4660 - val_AUC: 0.8685 - val_Precision: 0.9930 - val_Recall: 0.6234 - val_accuracy: 0.8290 - val_loss: 1.3418 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8789 - Precision: 0.8687 - Recall: 0.7476 - accuracy: 0.8368 - loss: 1.2332 - val_AUC: 0.8596 - val_Precision: 0.9868 - val_Recall: 0.6569 - val_accuracy: 0.8421 - val_loss: 1.1396 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8789 - Precision: 0.8687 - Recall: 0.7476 - accuracy: 0.8368 - loss: 1.2332 - val_AUC: 0.8596 - val_Precision: 0.9868 - val_Recall: 0.6569 - val_accuracy: 0.8421 - val_loss: 1.1396 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8793 - Precision: 0.8869 - Recall: 0.7568 - accuracy: 0.8483 - loss: 1.0521 - val_AUC: 0.8654 - val_Precision: 0.9935 - val_Recall: 0.6730 - val_accuracy: 0.8512 - val_loss: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8793 - Precision: 0.8869 - Recall: 0.7568 - accuracy: 0.8483 - loss: 1.0521 - val_AUC: 0.8654 - val_Precision: 0.9935 - val_Recall: 0.6730 - val_accuracy: 0.8512 - val_loss: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8844 - Precision: 0.8875 - Recall: 0.7553 - accuracy: 0.8479 - loss: 0.9123 - val_AUC: 0.8747 - val_Precision: 0.9874 - val_Recall: 0.6891 - val_accuracy: 0.8565 - val_loss: 0.8489 - learning_rate: 5.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8844 - Precision: 0.8875 - Recall: 0.7553 - accuracy: 0.8479 - loss: 0.9123 - val_AUC: 0.8747 - val_Precision: 0.9874 - val_Recall: 0.6891 - val_accuracy: 0.8565 - val_loss: 0.8489 - learning_rate: 5.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8888 - Precision: 0.8890 - Recall: 0.7641 - accuracy: 0.8520 - loss: 0.8040 - val_AUC: 0.8716 - val_Precision: 0.9813 - val_Recall: 0.6891 - val_accuracy: 0.8545 - val_loss: 0.7609 - learning_rate: 5.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8888 - Precision: 0.8890 - Recall: 0.7641 - accuracy: 0.8520 - loss: 0.8040 - val_AUC: 0.8716 - val_Precision: 0.9813 - val_Recall: 0.6891 - val_accuracy: 0.8545 - val_loss: 0.7609 - learning_rate: 5.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8822 - Precision: 0.9028 - Recall: 0.7564 - accuracy: 0.8548 - loss: 0.7302 - val_AUC: 0.8779 - val_Precision: 0.9851 - val_Recall: 0.6745 - val_accuracy: 0.8493 - val_loss: 0.6927 - learning_rate: 5.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8822 - Precision: 0.9028 - Recall: 0.7564 - accuracy: 0.8548 - loss: 0.7302 - val_AUC: 0.8779 - val_Precision: 0.9851 - val_Recall: 0.6745 - val_accuracy: 0.8493 - val_loss: 0.6927 - learning_rate: 5.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8859 - Precision: 0.9034 - Recall: 0.7619 - accuracy: 0.8573 - loss: 0.6644 - val_AUC: 0.8759 - val_Precision: 0.9894 - val_Recall: 0.6788 - val_accuracy: 0.8526 - val_loss: 0.6367 - learning_rate: 5.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8859 - Precision: 0.9034 - Recall: 0.7619 - accuracy: 0.8573 - loss: 0.6644 - val_AUC: 0.8759 - val_Precision: 0.9894 - val_Recall: 0.6788 - val_accuracy: 0.8526 - val_loss: 0.6367 - learning_rate: 5.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8852 - Precision: 0.9088 - Recall: 0.7568 - accuracy: 0.8574 - loss: 0.6189 - val_AUC: 0.8754 - val_Precision: 0.9832 - val_Recall: 0.6832 - val_accuracy: 0.8526 - val_loss: 0.5952 - learning_rate: 5.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8852 - Precision: 0.9088 - Recall: 0.7568 - accuracy: 0.8574 - loss: 0.6189 - val_AUC: 0.8754 - val_Precision: 0.9832 - val_Recall: 0.6832 - val_accuracy: 0.8526 - val_loss: 0.5952 - learning_rate: 5.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8863 - Precision: 0.9202 - Recall: 0.7572 - accuracy: 0.8622 - loss: 0.5755 - val_AUC: 0.8727 - val_Precision: 0.9834 - val_Recall: 0.6934 - val_accuracy: 0.8571 - val_loss: 0.5577 - learning_rate: 5.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8863 - Precision: 0.9202 - Recall: 0.7572 - accuracy: 0.8622 - loss: 0.5755 - val_AUC: 0.8727 - val_Precision: 0.9834 - val_Recall: 0.6934 - val_accuracy: 0.8571 - val_loss: 0.5577 - learning_rate: 5.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8860 - Precision: 0.9204 - Recall: 0.7638 - accuracy: 0.8650 - loss: 0.5456 - val_AUC: 0.8735 - val_Precision: 0.9801 - val_Recall: 0.7197 - val_accuracy: 0.8676 - val_loss: 0.5205 - learning_rate: 5.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8860 - Precision: 0.9204 - Recall: 0.7638 - accuracy: 0.8650 - loss: 0.5456 - val_AUC: 0.8735 - val_Precision: 0.9801 - val_Recall: 0.7197 - val_accuracy: 0.8676 - val_loss: 0.5205 - learning_rate: 5.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8879 - Precision: 0.9192 - Recall: 0.7682 - accuracy: 0.8663 - loss: 0.5218 - val_AUC: 0.8711 - val_Precision: 0.9794 - val_Recall: 0.6934 - val_accuracy: 0.8558 - val_loss: 0.5130 - learning_rate: 5.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8879 - Precision: 0.9192 - Recall: 0.7682 - accuracy: 0.8663 - loss: 0.5218 - val_AUC: 0.8711 - val_Precision: 0.9794 - val_Recall: 0.6934 - val_accuracy: 0.8558 - val_loss: 0.5130 - learning_rate: 5.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8884 - Precision: 0.9196 - Recall: 0.7597 - accuracy: 0.8630 - loss: 0.5071 - val_AUC: 0.8717 - val_Precision: 0.9740 - val_Recall: 0.7109 - val_accuracy: 0.8617 - val_loss: 0.4945 - learning_rate: 5.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8884 - Precision: 0.9196 - Recall: 0.7597 - accuracy: 0.8630 - loss: 0.5071 - val_AUC: 0.8717 - val_Precision: 0.9740 - val_Recall: 0.7109 - val_accuracy: 0.8617 - val_loss: 0.4945 - learning_rate: 5.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9285 - Recall: 0.7623 - accuracy: 0.8676 - loss: 0.4919 - val_AUC: 0.8716 - val_Precision: 0.9705 - val_Recall: 0.7212 - val_accuracy: 0.8650 - val_loss: 0.4755 - learning_rate: 5.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9285 - Recall: 0.7623 - accuracy: 0.8676 - loss: 0.4919 - val_AUC: 0.8716 - val_Precision: 0.9705 - val_Recall: 0.7212 - val_accuracy: 0.8650 - val_loss: 0.4755 - learning_rate: 5.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8854 - Precision: 0.9304 - Recall: 0.7605 - accuracy: 0.8676 - loss: 0.4808 - val_AUC: 0.8732 - val_Precision: 0.9595 - val_Recall: 0.7270 - val_accuracy: 0.8637 - val_loss: 0.4655 - learning_rate: 5.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8854 - Precision: 0.9304 - Recall: 0.7605 - accuracy: 0.8676 - loss: 0.4808 - val_AUC: 0.8732 - val_Precision: 0.9595 - val_Recall: 0.7270 - val_accuracy: 0.8637 - val_loss: 0.4655 - learning_rate: 5.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8878 - Precision: 0.9311 - Recall: 0.7682 - accuracy: 0.8710 - loss: 0.4656 - val_AUC: 0.8717 - val_Precision: 0.9746 - val_Recall: 0.7285 - val_accuracy: 0.8696 - val_loss: 0.4550 - learning_rate: 5.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8878 - Precision: 0.9311 - Recall: 0.7682 - accuracy: 0.8710 - loss: 0.4656 - val_AUC: 0.8717 - val_Precision: 0.9746 - val_Recall: 0.7285 - val_accuracy: 0.8696 - val_loss: 0.4550 - learning_rate: 5.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8810 - Precision: 0.9239 - Recall: 0.7616 - accuracy: 0.8655 - loss: 0.4724 - val_AUC: 0.8710 - val_Precision: 0.9783 - val_Recall: 0.7226 - val_accuracy: 0.8683 - val_loss: 0.4539 - learning_rate: 5.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8810 - Precision: 0.9239 - Recall: 0.7616 - accuracy: 0.8655 - loss: 0.4724 - val_AUC: 0.8710 - val_Precision: 0.9783 - val_Recall: 0.7226 - val_accuracy: 0.8683 - val_loss: 0.4539 - learning_rate: 5.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8899 - Precision: 0.9363 - Recall: 0.7660 - accuracy: 0.8722 - loss: 0.4507 - val_AUC: 0.8709 - val_Precision: 0.9763 - val_Recall: 0.7212 - val_accuracy: 0.8670 - val_loss: 0.4434 - learning_rate: 5.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8899 - Precision: 0.9363 - Recall: 0.7660 - accuracy: 0.8722 - loss: 0.4507 - val_AUC: 0.8709 - val_Precision: 0.9763 - val_Recall: 0.7212 - val_accuracy: 0.8670 - val_loss: 0.4434 - learning_rate: 5.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8907 - Precision: 0.9386 - Recall: 0.7685 - accuracy: 0.8742 - loss: 0.4427 - val_AUC: 0.8716 - val_Precision: 0.9692 - val_Recall: 0.7358 - val_accuracy: 0.8709 - val_loss: 0.4375 - learning_rate: 5.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8907 - Precision: 0.9386 - Recall: 0.7685 - accuracy: 0.8742 - loss: 0.4427 - val_AUC: 0.8716 - val_Precision: 0.9692 - val_Recall: 0.7358 - val_accuracy: 0.8709 - val_loss: 0.4375 - learning_rate: 5.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8931 - Precision: 0.9371 - Recall: 0.7645 - accuracy: 0.8719 - loss: 0.4362 - val_AUC: 0.8723 - val_Precision: 0.9673 - val_Recall: 0.7343 - val_accuracy: 0.8696 - val_loss: 0.4334 - learning_rate: 5.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8931 - Precision: 0.9371 - Recall: 0.7645 - accuracy: 0.8719 - loss: 0.4362 - val_AUC: 0.8723 - val_Precision: 0.9673 - val_Recall: 0.7343 - val_accuracy: 0.8696 - val_loss: 0.4334 - learning_rate: 5.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8841 - Precision: 0.9443 - Recall: 0.7594 - accuracy: 0.8725 - loss: 0.4419 - val_AUC: 0.8694 - val_Precision: 0.9750 - val_Recall: 0.7416 - val_accuracy: 0.8755 - val_loss: 0.4246 - learning_rate: 5.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8841 - Precision: 0.9443 - Recall: 0.7594 - accuracy: 0.8725 - loss: 0.4419 - val_AUC: 0.8694 - val_Precision: 0.9750 - val_Recall: 0.7416 - val_accuracy: 0.8755 - val_loss: 0.4246 - learning_rate: 5.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8894 - Precision: 0.9461 - Recall: 0.7663 - accuracy: 0.8761 - loss: 0.4299 - val_AUC: 0.8747 - val_Precision: 0.9674 - val_Recall: 0.7372 - val_accuracy: 0.8709 - val_loss: 0.4217 - learning_rate: 5.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8894 - Precision: 0.9461 - Recall: 0.7663 - accuracy: 0.8761 - loss: 0.4299 - val_AUC: 0.8747 - val_Precision: 0.9674 - val_Recall: 0.7372 - val_accuracy: 0.8709 - val_loss: 0.4217 - learning_rate: 5.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9408 - Recall: 0.7638 - accuracy: 0.8730 - loss: 0.4342 - val_AUC: 0.8685 - val_Precision: 0.9715 - val_Recall: 0.7460 - val_accuracy: 0.8761 - val_loss: 0.4174 - learning_rate: 5.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8871 - Precision: 0.9408 - Recall: 0.7638 - accuracy: 0.8730 - loss: 0.4342 - val_AUC: 0.8685 - val_Precision: 0.9715 - val_Recall: 0.7460 - val_accuracy: 0.8761 - val_loss: 0.4174 - learning_rate: 5.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8908 - Precision: 0.9487 - Recall: 0.7660 - accuracy: 0.8769 - loss: 0.4211 - val_AUC: 0.8629 - val_Precision: 0.9725 - val_Recall: 0.7241 - val_accuracy: 0.8670 - val_loss: 0.4274 - learning_rate: 5.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8908 - Precision: 0.9487 - Recall: 0.7660 - accuracy: 0.8769 - loss: 0.4211 - val_AUC: 0.8629 - val_Precision: 0.9725 - val_Recall: 0.7241 - val_accuracy: 0.8670 - val_loss: 0.4274 - learning_rate: 5.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8850 - Precision: 0.9478 - Recall: 0.7594 - accuracy: 0.8738 - loss: 0.4232 - val_AUC: 0.8714 - val_Precision: 0.9694 - val_Recall: 0.7401 - val_accuracy: 0.8729 - val_loss: 0.4085 - learning_rate: 5.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8850 - Precision: 0.9478 - Recall: 0.7594 - accuracy: 0.8738 - loss: 0.4232 - val_AUC: 0.8714 - val_Precision: 0.9694 - val_Recall: 0.7401 - val_accuracy: 0.8729 - val_loss: 0.4085 - learning_rate: 5.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8914 - Precision: 0.9543 - Recall: 0.7579 - accuracy: 0.8756 - loss: 0.4150 - val_AUC: 0.8642 - val_Precision: 0.9788 - val_Recall: 0.7431 - val_accuracy: 0.8775 - val_loss: 0.4003 - learning_rate: 5.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8914 - Precision: 0.9543 - Recall: 0.7579 - accuracy: 0.8756 - loss: 0.4150 - val_AUC: 0.8642 - val_Precision: 0.9788 - val_Recall: 0.7431 - val_accuracy: 0.8775 - val_loss: 0.4003 - learning_rate: 5.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8910 - Precision: 0.9552 - Recall: 0.7667 - accuracy: 0.8797 - loss: 0.4070 - val_AUC: 0.8706 - val_Precision: 0.9749 - val_Recall: 0.7372 - val_accuracy: 0.8735 - val_loss: 0.4077 - learning_rate: 5.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8910 - Precision: 0.9552 - Recall: 0.7667 - accuracy: 0.8797 - loss: 0.4070 - val_AUC: 0.8706 - val_Precision: 0.9749 - val_Recall: 0.7372 - val_accuracy: 0.8735 - val_loss: 0.4077 - learning_rate: 5.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8884 - Precision: 0.9510 - Recall: 0.7696 - accuracy: 0.8794 - loss: 0.4161 - val_AUC: 0.8753 - val_Precision: 0.9639 - val_Recall: 0.7416 - val_accuracy: 0.8716 - val_loss: 0.4064 - learning_rate: 5.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8884 - Precision: 0.9510 - Recall: 0.7696 - accuracy: 0.8794 - loss: 0.4161 - val_AUC: 0.8753 - val_Precision: 0.9639 - val_Recall: 0.7416 - val_accuracy: 0.8716 - val_loss: 0.4064 - learning_rate: 5.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - AUC: 0.8883 - Precision: 0.9500 - Recall: 0.7671 - accuracy: 0.8779 - loss: 0.4113 - val_AUC: 0.8710 - val_Precision: 0.9733 - val_Recall: 0.7445 - val_accuracy: 0.8761 - val_loss: 0.3996 - learning_rate: 5.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - AUC: 0.8883 - Precision: 0.9500 - Recall: 0.7671 - accuracy: 0.8779 - loss: 0.4113 - val_AUC: 0.8710 - val_Precision: 0.9733 - val_Recall: 0.7445 - val_accuracy: 0.8761 - val_loss: 0.3996 - learning_rate: 5.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8901 - Precision: 0.9565 - Recall: 0.7656 - accuracy: 0.8797 - loss: 0.4104 - val_AUC: 0.8695 - val_Precision: 0.9532 - val_Recall: 0.7431 - val_accuracy: 0.8683 - val_loss: 0.4123 - learning_rate: 5.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8901 - Precision: 0.9565 - Recall: 0.7656 - accuracy: 0.8797 - loss: 0.4104 - val_AUC: 0.8695 - val_Precision: 0.9532 - val_Recall: 0.7431 - val_accuracy: 0.8683 - val_loss: 0.4123 - learning_rate: 5.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8905 - Precision: 0.9505 - Recall: 0.7685 - accuracy: 0.8787 - loss: 0.4102 - val_AUC: 0.8689 - val_Precision: 0.9662 - val_Recall: 0.7504 - val_accuracy: 0.8761 - val_loss: 0.3951 - learning_rate: 5.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.8905 - Precision: 0.9505 - Recall: 0.7685 - accuracy: 0.8787 - loss: 0.4102 - val_AUC: 0.8689 - val_Precision: 0.9662 - val_Recall: 0.7504 - val_accuracy: 0.8761 - val_loss: 0.3951 - learning_rate: 5.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8915 - Precision: 0.9540 - Recall: 0.7689 - accuracy: 0.8802 - loss: 0.4008 - val_AUC: 0.8721 - val_Precision: 0.9862 - val_Recall: 0.7299 - val_accuracy: 0.8742 - val_loss: 0.3973 - learning_rate: 5.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8915 - Precision: 0.9540 - Recall: 0.7689 - accuracy: 0.8802 - loss: 0.4008 - val_AUC: 0.8721 - val_Precision: 0.9862 - val_Recall: 0.7299 - val_accuracy: 0.8742 - val_loss: 0.3973 - learning_rate: 5.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8876 - Precision: 0.9592 - Recall: 0.7597 - accuracy: 0.8783 - loss: 0.4060 - val_AUC: 0.8720 - val_Precision: 0.9769 - val_Recall: 0.7401 - val_accuracy: 0.8755 - val_loss: 0.4007 - learning_rate: 5.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8876 - Precision: 0.9592 - Recall: 0.7597 - accuracy: 0.8783 - loss: 0.4060 - val_AUC: 0.8720 - val_Precision: 0.9769 - val_Recall: 0.7401 - val_accuracy: 0.8755 - val_loss: 0.4007 - learning_rate: 5.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8930 - Precision: 0.9597 - Recall: 0.7696 - accuracy: 0.8827 - loss: 0.3975 - val_AUC: 0.8699 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3939 - learning_rate: 5.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8930 - Precision: 0.9597 - Recall: 0.7696 - accuracy: 0.8827 - loss: 0.3975 - val_AUC: 0.8699 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3939 - learning_rate: 5.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8924 - Precision: 0.9590 - Recall: 0.7630 - accuracy: 0.8796 - loss: 0.4006 - val_AUC: 0.8702 - val_Precision: 0.9846 - val_Recall: 0.7489 - val_accuracy: 0.8820 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8924 - Precision: 0.9590 - Recall: 0.7630 - accuracy: 0.8796 - loss: 0.4006 - val_AUC: 0.8702 - val_Precision: 0.9846 - val_Recall: 0.7489 - val_accuracy: 0.8820 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8856 - Precision: 0.9564 - Recall: 0.7645 - accuracy: 0.8792 - loss: 0.4023 - val_AUC: 0.8667 - val_Precision: 0.9661 - val_Recall: 0.7489 - val_accuracy: 0.8755 - val_loss: 0.3928 - learning_rate: 5.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8856 - Precision: 0.9564 - Recall: 0.7645 - accuracy: 0.8792 - loss: 0.4023 - val_AUC: 0.8667 - val_Precision: 0.9661 - val_Recall: 0.7489 - val_accuracy: 0.8755 - val_loss: 0.3928 - learning_rate: 5.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8908 - Precision: 0.9622 - Recall: 0.7663 - accuracy: 0.8822 - loss: 0.3975 - val_AUC: 0.8676 - val_Precision: 0.9789 - val_Recall: 0.7445 - val_accuracy: 0.8781 - val_loss: 0.3898 - learning_rate: 5.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8908 - Precision: 0.9622 - Recall: 0.7663 - accuracy: 0.8822 - loss: 0.3975 - val_AUC: 0.8676 - val_Precision: 0.9789 - val_Recall: 0.7445 - val_accuracy: 0.8781 - val_loss: 0.3898 - learning_rate: 5.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8844 - Precision: 0.9638 - Recall: 0.7619 - accuracy: 0.8809 - loss: 0.3982 - val_AUC: 0.8670 - val_Precision: 0.9844 - val_Recall: 0.7387 - val_accuracy: 0.8775 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8844 - Precision: 0.9638 - Recall: 0.7619 - accuracy: 0.8809 - loss: 0.3982 - val_AUC: 0.8670 - val_Precision: 0.9844 - val_Recall: 0.7387 - val_accuracy: 0.8775 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - AUC: 0.8912 - Precision: 0.9625 - Recall: 0.7623 - accuracy: 0.8806 - loss: 0.3891 - val_AUC: 0.8687 - val_Precision: 0.9807 - val_Recall: 0.7431 - val_accuracy: 0.8781 - val_loss: 0.3904 - learning_rate: 5.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - AUC: 0.8912 - Precision: 0.9625 - Recall: 0.7623 - accuracy: 0.8806 - loss: 0.3891 - val_AUC: 0.8687 - val_Precision: 0.9807 - val_Recall: 0.7431 - val_accuracy: 0.8781 - val_loss: 0.3904 - learning_rate: 5.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.8872 - Precision: 0.9615 - Recall: 0.7608 - accuracy: 0.8796 - loss: 0.3981 - val_AUC: 0.8664 - val_Precision: 0.9751 - val_Recall: 0.7431 - val_accuracy: 0.8761 - val_loss: 0.3912 - learning_rate: 5.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.8872 - Precision: 0.9615 - Recall: 0.7608 - accuracy: 0.8796 - loss: 0.3981 - val_AUC: 0.8664 - val_Precision: 0.9751 - val_Recall: 0.7431 - val_accuracy: 0.8761 - val_loss: 0.3912 - learning_rate: 5.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.8930 - Precision: 0.9586 - Recall: 0.7649 - accuracy: 0.8802 - loss: 0.3965 - val_AUC: 0.8655 - val_Precision: 0.9696 - val_Recall: 0.7445 - val_accuracy: 0.8748 - val_loss: 0.3926 - learning_rate: 5.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.8930 - Precision: 0.9586 - Recall: 0.7649 - accuracy: 0.8802 - loss: 0.3965 - val_AUC: 0.8655 - val_Precision: 0.9696 - val_Recall: 0.7445 - val_accuracy: 0.8748 - val_loss: 0.3926 - learning_rate: 5.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m93/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8869 - Precision: 0.9664 - Recall: 0.7655 - accuracy: 0.8818 - loss: 0.4000\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - AUC: 0.8897 - Precision: 0.9630 - Recall: 0.7641 - accuracy: 0.8815 - loss: 0.3943 - val_AUC: 0.8696 - val_Precision: 0.9643 - val_Recall: 0.7489 - val_accuracy: 0.8748 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - AUC: 0.8897 - Precision: 0.9630 - Recall: 0.7641 - accuracy: 0.8815 - loss: 0.3943 - val_AUC: 0.8696 - val_Precision: 0.9643 - val_Recall: 0.7489 - val_accuracy: 0.8748 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.8991 - Precision: 0.9732 - Recall: 0.7726 - accuracy: 0.8889 - loss: 0.3748 - val_AUC: 0.8717 - val_Precision: 0.9846 - val_Recall: 0.7460 - val_accuracy: 0.8807 - val_loss: 0.3800 - learning_rate: 1.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.8991 - Precision: 0.9732 - Recall: 0.7726 - accuracy: 0.8889 - loss: 0.3748 - val_AUC: 0.8717 - val_Precision: 0.9846 - val_Recall: 0.7460 - val_accuracy: 0.8807 - val_loss: 0.3800 - learning_rate: 1.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.9032 - Precision: 0.9738 - Recall: 0.7784 - accuracy: 0.8917 - loss: 0.3636 - val_AUC: 0.8712 - val_Precision: 0.9846 - val_Recall: 0.7474 - val_accuracy: 0.8814 - val_loss: 0.3760 - learning_rate: 1.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.9032 - Precision: 0.9738 - Recall: 0.7784 - accuracy: 0.8917 - loss: 0.3636 - val_AUC: 0.8712 - val_Precision: 0.9846 - val_Recall: 0.7474 - val_accuracy: 0.8814 - val_loss: 0.3760 - learning_rate: 1.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.9067 - Precision: 0.9732 - Recall: 0.7847 - accuracy: 0.8942 - loss: 0.3555 - val_AUC: 0.8707 - val_Precision: 0.9827 - val_Recall: 0.7460 - val_accuracy: 0.8801 - val_loss: 0.3737 - learning_rate: 1.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - AUC: 0.9067 - Precision: 0.9732 - Recall: 0.7847 - accuracy: 0.8942 - loss: 0.3555 - val_AUC: 0.8707 - val_Precision: 0.9827 - val_Recall: 0.7460 - val_accuracy: 0.8801 - val_loss: 0.3737 - learning_rate: 1.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - AUC: 0.9098 - Precision: 0.9688 - Recall: 0.7850 - accuracy: 0.8927 - loss: 0.3506 - val_AUC: 0.8696 - val_Precision: 0.9827 - val_Recall: 0.7460 - val_accuracy: 0.8801 - val_loss: 0.3744 - learning_rate: 1.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - AUC: 0.9098 - Precision: 0.9688 - Recall: 0.7850 - accuracy: 0.8927 - loss: 0.3506 - val_AUC: 0.8696 - val_Precision: 0.9827 - val_Recall: 0.7460 - val_accuracy: 0.8801 - val_loss: 0.3744 - learning_rate: 1.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9122 - Precision: 0.9719 - Recall: 0.7880 - accuracy: 0.8951 - loss: 0.3434 - val_AUC: 0.8661 - val_Precision: 0.9808 - val_Recall: 0.7474 - val_accuracy: 0.8801 - val_loss: 0.3719 - learning_rate: 1.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9122 - Precision: 0.9719 - Recall: 0.7880 - accuracy: 0.8951 - loss: 0.3434 - val_AUC: 0.8661 - val_Precision: 0.9808 - val_Recall: 0.7474 - val_accuracy: 0.8801 - val_loss: 0.3719 - learning_rate: 1.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9173 - Precision: 0.9735 - Recall: 0.7938 - accuracy: 0.8982 - loss: 0.3382 - val_AUC: 0.8678 - val_Precision: 0.9771 - val_Recall: 0.7460 - val_accuracy: 0.8781 - val_loss: 0.3724 - learning_rate: 1.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9173 - Precision: 0.9735 - Recall: 0.7938 - accuracy: 0.8982 - loss: 0.3382 - val_AUC: 0.8678 - val_Precision: 0.9771 - val_Recall: 0.7460 - val_accuracy: 0.8781 - val_loss: 0.3724 - learning_rate: 1.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9149 - Precision: 0.9729 - Recall: 0.7887 - accuracy: 0.8958 - loss: 0.3371 - val_AUC: 0.8681 - val_Precision: 0.9789 - val_Recall: 0.7460 - val_accuracy: 0.8788 - val_loss: 0.3705 - learning_rate: 1.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9149 - Precision: 0.9729 - Recall: 0.7887 - accuracy: 0.8958 - loss: 0.3371 - val_AUC: 0.8681 - val_Precision: 0.9789 - val_Recall: 0.7460 - val_accuracy: 0.8788 - val_loss: 0.3705 - learning_rate: 1.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9204 - Precision: 0.9739 - Recall: 0.7942 - accuracy: 0.8986 - loss: 0.3313 - val_AUC: 0.8676 - val_Precision: 0.9770 - val_Recall: 0.7445 - val_accuracy: 0.8775 - val_loss: 0.3729 - learning_rate: 1.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9204 - Precision: 0.9739 - Recall: 0.7942 - accuracy: 0.8986 - loss: 0.3313 - val_AUC: 0.8676 - val_Precision: 0.9770 - val_Recall: 0.7445 - val_accuracy: 0.8775 - val_loss: 0.3729 - learning_rate: 1.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9195 - Precision: 0.9700 - Recall: 0.7946 - accuracy: 0.8973 - loss: 0.3320 - val_AUC: 0.8690 - val_Precision: 0.9771 - val_Recall: 0.7489 - val_accuracy: 0.8794 - val_loss: 0.3726 - learning_rate: 1.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9195 - Precision: 0.9700 - Recall: 0.7946 - accuracy: 0.8973 - loss: 0.3320 - val_AUC: 0.8690 - val_Precision: 0.9771 - val_Recall: 0.7489 - val_accuracy: 0.8794 - val_loss: 0.3726 - learning_rate: 1.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9195 - Precision: 0.9696 - Recall: 0.7949 - accuracy: 0.8973 - loss: 0.3296 - val_AUC: 0.8700 - val_Precision: 0.9718 - val_Recall: 0.7533 - val_accuracy: 0.8794 - val_loss: 0.3727 - learning_rate: 1.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9195 - Precision: 0.9696 - Recall: 0.7949 - accuracy: 0.8973 - loss: 0.3296 - val_AUC: 0.8700 - val_Precision: 0.9718 - val_Recall: 0.7533 - val_accuracy: 0.8794 - val_loss: 0.3727 - learning_rate: 1.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9210 - Precision: 0.9709 - Recall: 0.7946 - accuracy: 0.8976 - loss: 0.3289 - val_AUC: 0.8677 - val_Precision: 0.9696 - val_Recall: 0.7460 - val_accuracy: 0.8755 - val_loss: 0.3770 - learning_rate: 1.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9210 - Precision: 0.9709 - Recall: 0.7946 - accuracy: 0.8976 - loss: 0.3289 - val_AUC: 0.8677 - val_Precision: 0.9696 - val_Recall: 0.7460 - val_accuracy: 0.8755 - val_loss: 0.3770 - learning_rate: 1.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9236 - Precision: 0.9683 - Recall: 0.7968 - accuracy: 0.8976 - loss: 0.3228 - val_AUC: 0.8674 - val_Precision: 0.9734 - val_Recall: 0.7474 - val_accuracy: 0.8775 - val_loss: 0.3741 - learning_rate: 1.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9236 - Precision: 0.9683 - Recall: 0.7968 - accuracy: 0.8976 - loss: 0.3228 - val_AUC: 0.8674 - val_Precision: 0.9734 - val_Recall: 0.7474 - val_accuracy: 0.8775 - val_loss: 0.3741 - learning_rate: 1.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9259 - Precision: 0.9645 - Recall: 0.7982 - accuracy: 0.8968 - loss: 0.3225 - val_AUC: 0.8674 - val_Precision: 0.9790 - val_Recall: 0.7474 - val_accuracy: 0.8794 - val_loss: 0.3725 - learning_rate: 1.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9259 - Precision: 0.9645 - Recall: 0.7982 - accuracy: 0.8968 - loss: 0.3225 - val_AUC: 0.8674 - val_Precision: 0.9790 - val_Recall: 0.7474 - val_accuracy: 0.8794 - val_loss: 0.3725 - learning_rate: 1.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9212 - Precision: 0.9667 - Recall: 0.7975 - accuracy: 0.8973 - loss: 0.3255 - val_AUC: 0.8679 - val_Precision: 0.9808 - val_Recall: 0.7460 - val_accuracy: 0.8794 - val_loss: 0.3703 - learning_rate: 1.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9212 - Precision: 0.9667 - Recall: 0.7975 - accuracy: 0.8973 - loss: 0.3255 - val_AUC: 0.8679 - val_Precision: 0.9808 - val_Recall: 0.7460 - val_accuracy: 0.8794 - val_loss: 0.3703 - learning_rate: 1.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9292 - Precision: 0.9691 - Recall: 0.8045 - accuracy: 0.9012 - loss: 0.3159 - val_AUC: 0.8687 - val_Precision: 0.9715 - val_Recall: 0.7474 - val_accuracy: 0.8768 - val_loss: 0.3780 - learning_rate: 1.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9292 - Precision: 0.9691 - Recall: 0.8045 - accuracy: 0.9012 - loss: 0.3159 - val_AUC: 0.8687 - val_Precision: 0.9715 - val_Recall: 0.7474 - val_accuracy: 0.8768 - val_loss: 0.3780 - learning_rate: 1.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9292 - Precision: 0.9643 - Recall: 0.8034 - accuracy: 0.8989 - loss: 0.3168 - val_AUC: 0.8699 - val_Precision: 0.9680 - val_Recall: 0.7504 - val_accuracy: 0.8768 - val_loss: 0.3773 - learning_rate: 1.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9292 - Precision: 0.9643 - Recall: 0.8034 - accuracy: 0.8989 - loss: 0.3168 - val_AUC: 0.8699 - val_Precision: 0.9680 - val_Recall: 0.7504 - val_accuracy: 0.8768 - val_loss: 0.3773 - learning_rate: 1.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9279 - Precision: 0.9667 - Recall: 0.7997 - accuracy: 0.8982 - loss: 0.3198 - val_AUC: 0.8704 - val_Precision: 0.9753 - val_Recall: 0.7504 - val_accuracy: 0.8794 - val_loss: 0.3772 - learning_rate: 1.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9279 - Precision: 0.9667 - Recall: 0.7997 - accuracy: 0.8982 - loss: 0.3198 - val_AUC: 0.8704 - val_Precision: 0.9753 - val_Recall: 0.7504 - val_accuracy: 0.8794 - val_loss: 0.3772 - learning_rate: 1.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9310 - Precision: 0.9609 - Recall: 0.8019 - accuracy: 0.8969 - loss: 0.3151 - val_AUC: 0.8673 - val_Precision: 0.9751 - val_Recall: 0.7445 - val_accuracy: 0.8768 - val_loss: 0.3804 - learning_rate: 1.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9310 - Precision: 0.9609 - Recall: 0.8019 - accuracy: 0.8969 - loss: 0.3151 - val_AUC: 0.8673 - val_Precision: 0.9751 - val_Recall: 0.7445 - val_accuracy: 0.8768 - val_loss: 0.3804 - learning_rate: 1.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9314 - Precision: 0.9696 - Recall: 0.8074 - accuracy: 0.9027 - loss: 0.3117 - val_AUC: 0.8668 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3842 - learning_rate: 1.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9314 - Precision: 0.9696 - Recall: 0.8074 - accuracy: 0.9027 - loss: 0.3117 - val_AUC: 0.8668 - val_Precision: 0.9716 - val_Recall: 0.7489 - val_accuracy: 0.8775 - val_loss: 0.3842 - learning_rate: 1.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9308 - Precision: 0.9665 - Recall: 0.8048 - accuracy: 0.9004 - loss: 0.3147 - val_AUC: 0.8704 - val_Precision: 0.9680 - val_Recall: 0.7504 - val_accuracy: 0.8768 - val_loss: 0.3757 - learning_rate: 1.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9308 - Precision: 0.9665 - Recall: 0.8048 - accuracy: 0.9004 - loss: 0.3147 - val_AUC: 0.8704 - val_Precision: 0.9680 - val_Recall: 0.7504 - val_accuracy: 0.8768 - val_loss: 0.3757 - learning_rate: 1.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m89/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9310 - Precision: 0.9635 - Recall: 0.8084 - accuracy: 0.8993 - loss: 0.3147\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9341 - Precision: 0.9637 - Recall: 0.8074 - accuracy: 0.9004 - loss: 0.3088 - val_AUC: 0.8700 - val_Precision: 0.9771 - val_Recall: 0.7474 - val_accuracy: 0.8788 - val_loss: 0.3770 - learning_rate: 1.0000e-04\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9341 - Precision: 0.9637 - Recall: 0.8074 - accuracy: 0.9004 - loss: 0.3088 - val_AUC: 0.8700 - val_Precision: 0.9771 - val_Recall: 0.7474 - val_accuracy: 0.8788 - val_loss: 0.3770 - learning_rate: 1.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9383 - Precision: 0.9744 - Recall: 0.8100 - accuracy: 0.9056 - loss: 0.3010 - val_AUC: 0.8708 - val_Precision: 0.9679 - val_Recall: 0.7474 - val_accuracy: 0.8755 - val_loss: 0.3791 - learning_rate: 2.0000e-05\n",
      "Epoch 71/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9383 - Precision: 0.9744 - Recall: 0.8100 - accuracy: 0.9056 - loss: 0.3010 - val_AUC: 0.8708 - val_Precision: 0.9679 - val_Recall: 0.7474 - val_accuracy: 0.8755 - val_loss: 0.3791 - learning_rate: 2.0000e-05\n",
      "Epoch 71/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9404 - Precision: 0.9660 - Recall: 0.8133 - accuracy: 0.9038 - loss: 0.2983 - val_AUC: 0.8707 - val_Precision: 0.9662 - val_Recall: 0.7504 - val_accuracy: 0.8761 - val_loss: 0.3819 - learning_rate: 2.0000e-05\n",
      "Epoch 72/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9404 - Precision: 0.9660 - Recall: 0.8133 - accuracy: 0.9038 - loss: 0.2983 - val_AUC: 0.8707 - val_Precision: 0.9662 - val_Recall: 0.7504 - val_accuracy: 0.8761 - val_loss: 0.3819 - learning_rate: 2.0000e-05\n",
      "Epoch 72/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9405 - Precision: 0.9670 - Recall: 0.8173 - accuracy: 0.9059 - loss: 0.2977 - val_AUC: 0.8710 - val_Precision: 0.9643 - val_Recall: 0.7489 - val_accuracy: 0.8748 - val_loss: 0.3831 - learning_rate: 2.0000e-05\n",
      "Epoch 73/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9405 - Precision: 0.9670 - Recall: 0.8173 - accuracy: 0.9059 - loss: 0.2977 - val_AUC: 0.8710 - val_Precision: 0.9643 - val_Recall: 0.7489 - val_accuracy: 0.8748 - val_loss: 0.3831 - learning_rate: 2.0000e-05\n",
      "Epoch 73/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9418 - Precision: 0.9637 - Recall: 0.8184 - accuracy: 0.9051 - loss: 0.2961 - val_AUC: 0.8710 - val_Precision: 0.9661 - val_Recall: 0.7489 - val_accuracy: 0.8755 - val_loss: 0.3849 - learning_rate: 2.0000e-05\n",
      "Epoch 74/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9418 - Precision: 0.9637 - Recall: 0.8184 - accuracy: 0.9051 - loss: 0.2961 - val_AUC: 0.8710 - val_Precision: 0.9661 - val_Recall: 0.7489 - val_accuracy: 0.8755 - val_loss: 0.3849 - learning_rate: 2.0000e-05\n",
      "Epoch 74/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9437 - Precision: 0.9646 - Recall: 0.8191 - accuracy: 0.9058 - loss: 0.2918 - val_AUC: 0.8710 - val_Precision: 0.9697 - val_Recall: 0.7474 - val_accuracy: 0.8761 - val_loss: 0.3843 - learning_rate: 2.0000e-05\n",
      "Epoch 75/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9437 - Precision: 0.9646 - Recall: 0.8191 - accuracy: 0.9058 - loss: 0.2918 - val_AUC: 0.8710 - val_Precision: 0.9697 - val_Recall: 0.7474 - val_accuracy: 0.8761 - val_loss: 0.3843 - learning_rate: 2.0000e-05\n",
      "Epoch 75/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9444 - Precision: 0.9651 - Recall: 0.8206 - accuracy: 0.9066 - loss: 0.2893 - val_AUC: 0.8697 - val_Precision: 0.9679 - val_Recall: 0.7474 - val_accuracy: 0.8755 - val_loss: 0.3884 - learning_rate: 2.0000e-05\n",
      "Epoch 76/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9444 - Precision: 0.9651 - Recall: 0.8206 - accuracy: 0.9066 - loss: 0.2893 - val_AUC: 0.8697 - val_Precision: 0.9679 - val_Recall: 0.7474 - val_accuracy: 0.8755 - val_loss: 0.3884 - learning_rate: 2.0000e-05\n",
      "Epoch 76/300\n",
      "\u001b[1m90/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9426 - Precision: 0.9688 - Recall: 0.8197 - accuracy: 0.9064 - loss: 0.2915\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9443 - Precision: 0.9675 - Recall: 0.8199 - accuracy: 0.9073 - loss: 0.2885 - val_AUC: 0.8697 - val_Precision: 0.9697 - val_Recall: 0.7474 - val_accuracy: 0.8761 - val_loss: 0.3889 - learning_rate: 2.0000e-05\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9443 - Precision: 0.9675 - Recall: 0.8199 - accuracy: 0.9073 - loss: 0.2885 - val_AUC: 0.8697 - val_Precision: 0.9697 - val_Recall: 0.7474 - val_accuracy: 0.8761 - val_loss: 0.3889 - learning_rate: 2.0000e-05\n",
      "Epoch 77/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9454 - Precision: 0.9660 - Recall: 0.8236 - accuracy: 0.9082 - loss: 0.2875 - val_AUC: 0.8700 - val_Precision: 0.9679 - val_Recall: 0.7474 - val_accuracy: 0.8755 - val_loss: 0.3882 - learning_rate: 4.0000e-06\n",
      "Epoch 78/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9454 - Precision: 0.9660 - Recall: 0.8236 - accuracy: 0.9082 - loss: 0.2875 - val_AUC: 0.8700 - val_Precision: 0.9679 - val_Recall: 0.7474 - val_accuracy: 0.8755 - val_loss: 0.3882 - learning_rate: 4.0000e-06\n",
      "Epoch 78/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9476 - Precision: 0.9630 - Recall: 0.8213 - accuracy: 0.9061 - loss: 0.2861 - val_AUC: 0.8700 - val_Precision: 0.9642 - val_Recall: 0.7474 - val_accuracy: 0.8742 - val_loss: 0.3893 - learning_rate: 4.0000e-06\n",
      "Epoch 79/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9476 - Precision: 0.9630 - Recall: 0.8213 - accuracy: 0.9061 - loss: 0.2861 - val_AUC: 0.8700 - val_Precision: 0.9642 - val_Recall: 0.7474 - val_accuracy: 0.8742 - val_loss: 0.3893 - learning_rate: 4.0000e-06\n",
      "Epoch 79/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9473 - Precision: 0.9648 - Recall: 0.8254 - accuracy: 0.9086 - loss: 0.2837 - val_AUC: 0.8700 - val_Precision: 0.9642 - val_Recall: 0.7474 - val_accuracy: 0.8742 - val_loss: 0.3898 - learning_rate: 4.0000e-06\n",
      "Epoch 80/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9473 - Precision: 0.9648 - Recall: 0.8254 - accuracy: 0.9086 - loss: 0.2837 - val_AUC: 0.8700 - val_Precision: 0.9642 - val_Recall: 0.7474 - val_accuracy: 0.8742 - val_loss: 0.3898 - learning_rate: 4.0000e-06\n",
      "Epoch 80/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9490 - Precision: 0.9685 - Recall: 0.8247 - accuracy: 0.9097 - loss: 0.2809 - val_AUC: 0.8704 - val_Precision: 0.9643 - val_Recall: 0.7489 - val_accuracy: 0.8748 - val_loss: 0.3902 - learning_rate: 4.0000e-06\n",
      "Epoch 81/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9490 - Precision: 0.9685 - Recall: 0.8247 - accuracy: 0.9097 - loss: 0.2809 - val_AUC: 0.8704 - val_Precision: 0.9643 - val_Recall: 0.7489 - val_accuracy: 0.8748 - val_loss: 0.3902 - learning_rate: 4.0000e-06\n",
      "Epoch 81/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9483 - Precision: 0.9630 - Recall: 0.8221 - accuracy: 0.9064 - loss: 0.2833 - val_AUC: 0.8705 - val_Precision: 0.9624 - val_Recall: 0.7474 - val_accuracy: 0.8735 - val_loss: 0.3915 - learning_rate: 4.0000e-06\n",
      "Epoch 82/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.9483 - Precision: 0.9630 - Recall: 0.8221 - accuracy: 0.9064 - loss: 0.2833 - val_AUC: 0.8705 - val_Precision: 0.9624 - val_Recall: 0.7474 - val_accuracy: 0.8735 - val_loss: 0.3915 - learning_rate: 4.0000e-06\n",
      "Epoch 82/300\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9475 - Precision: 0.9576 - Recall: 0.8291 - accuracy: 0.9073 - loss: 0.2845 - val_AUC: 0.8707 - val_Precision: 0.9606 - val_Recall: 0.7474 - val_accuracy: 0.8729 - val_loss: 0.3904 - learning_rate: 4.0000e-06\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.9475 - Precision: 0.9576 - Recall: 0.8291 - accuracy: 0.9073 - loss: 0.2845 - val_AUC: 0.8707 - val_Precision: 0.9606 - val_Recall: 0.7474 - val_accuracy: 0.8729 - val_loss: 0.3904 - learning_rate: 4.0000e-06\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "\n",
      "==================== LAST EPOCH RESULTS ====================\n",
      "Epoch 82\n",
      "Train Accuracy : 90.73%\n",
      "Val Accuracy   : 87.29%\n",
      "Train Loss     : 0.2845\n",
      "Val Loss       : 0.3904\n",
      "\n",
      "==================== LAST EPOCH RESULTS ====================\n",
      "Epoch 82\n",
      "Train Accuracy : 90.73%\n",
      "Val Accuracy   : 87.29%\n",
      "Train Loss     : 0.2845\n",
      "Val Loss       : 0.3904\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 112\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain Loss     : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m][last_epoch]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal Loss       : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory.history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m][last_epoch]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain AUC      : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mhistory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mauc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[last_epoch]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal AUC        : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory.history[\u001b[33m'\u001b[39m\u001b[33mval_auc\u001b[39m\u001b[33m'\u001b[39m][last_epoch]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    114\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m============================================================\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'auc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"Sheets/cybersecurity_intrusion_data.csv\")\n",
    "data = data.drop('session_id', axis=1)\n",
    "\n",
    "# Enhanced Feature Engineering\n",
    "data['failed_ratio'] = data['failed_logins'] / (data['login_attempts'] + 1)\n",
    "data['data_rate'] = data['network_packet_size'] / (data['session_duration'] + 1)\n",
    "data['high_risk'] = ((data['ip_reputation_score'] < 0.4) & \n",
    "                     (data['unusual_time_access'] > 0.6)).astype(int)\n",
    "data['activity_score'] = (data['network_packet_size'] * data['login_attempts']) / \\\n",
    "                        (data['session_duration'] + 1)\n",
    "data['risk_score'] = (1 - data['ip_reputation_score']) * data['unusual_time_access']\n",
    "data['login_frequency'] = data['login_attempts'] / (data['session_duration'] + 1)\n",
    "data['packet_size_per_login'] = data['network_packet_size'] / (data['login_attempts'] + 1)\n",
    "data['risk_activity_ratio'] = data['risk_score'] * data['activity_score']\n",
    "\n",
    "# Interaction features\n",
    "data['high_risk_failed'] = data['high_risk'] * data['failed_ratio']\n",
    "data['risk_login_freq'] = data['risk_score'] * data['login_frequency']\n",
    "\n",
    "# Handle categorical features\n",
    "categorical_cols = ['protocol_type', 'encryption_used', 'browser_type']\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "encoded = encoder.fit_transform(data[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Combine all features\n",
    "data = pd.concat([data.drop(columns=categorical_cols).reset_index(drop=True),\n",
    "                 encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Replace infinities and normalize features\n",
    "data = data.replace([np.inf, -np.inf], np.nan)\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "X = data.drop('attack_detected', axis=1)\n",
    "y = data['attack_detected']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "X_train_scaled = power.fit_transform(scaler.fit_transform(X_train))\n",
    "X_test_scaled = power.transform(scaler.transform(X_test))\n",
    "\n",
    "# Class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train_scaled.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=300,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history.history['auc'], label='Train AUC')\n",
    "plt.plot(history.history['val_auc'], label='Val AUC')\n",
    "plt.title('Model AUC')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predictions\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Attack', 'Attack']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Attack', 'Attack'],\n",
    "            yticklabels=['No Attack', 'Attack'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "model.save(\"cybersecurity_intrusion_ann_model_v2.h5\")\n",
    "print(\"\\nImproved model saved as 'cybersecurity_intrusion_ann_model_v2.h5'\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = np.abs(model.layers[0].get_weights()[0]).mean(axis=1)\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature')\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
